<!DOCTYPE html>
<html lang="zh-CN">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="Hadoop平台架构--硬件篇">




  <meta name="keywords" content="hadoop,">





  <link rel="alternate" href="/atom.xml" title="WHOAMI">




  <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/itweet/itweet.github.io/master/favicon.ico?v=1.1">



<link rel="canonical" href="http://itweet.github.io/2016/01/26/Hadoop-par1/">


<meta name="description" content="还记得刚接触Hadoop的时候,还是1.x版本,硬是在自己的4GB内存上面弄了3个虚拟机学习,条件有些艰苦,Hadoop测试集群搭建不需要太多考虑,随着毕业开始进入企业,在企业中实践Hadoop,特别是一定规模的集群,逐渐涉及到硬件资源,网络规划,操作系统,软件栈等一系列问题！对于一个没有经验的小白来说,还是比较复杂的,还好公司有linux大牛配合上我从各种技术网站博客吸收的微薄知识，从0开始">
<meta name="keywords" content="hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop平台架构--硬件篇">
<meta property="og:url" content="http://itweet.github.io/2016/01/26/Hadoop-par1/index.html">
<meta property="og:site_name" content="WHOAMI">
<meta property="og:description" content="还记得刚接触Hadoop的时候,还是1.x版本,硬是在自己的4GB内存上面弄了3个虚拟机学习,条件有些艰苦,Hadoop测试集群搭建不需要太多考虑,随着毕业开始进入企业,在企业中实践Hadoop,特别是一定规模的集群,逐渐涉及到硬件资源,网络规划,操作系统,软件栈等一系列问题！对于一个没有经验的小白来说,还是比较复杂的,还好公司有linux大牛配合上我从各种技术网站博客吸收的微薄知识，从0开始">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://www.itweet.cn/screenshots/hardware-disk.png">
<meta property="og:image" content="https://www.itweet.cn/screenshots/hardware-disk-2.png">
<meta property="og:updated_time" content="2019-12-25T14:39:06.114Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop平台架构--硬件篇">
<meta name="twitter:description" content="还记得刚接触Hadoop的时候,还是1.x版本,硬是在自己的4GB内存上面弄了3个虚拟机学习,条件有些艰苦,Hadoop测试集群搭建不需要太多考虑,随着毕业开始进入企业,在企业中实践Hadoop,特别是一定规模的集群,逐渐涉及到硬件资源,网络规划,操作系统,软件栈等一系列问题！对于一个没有经验的小白来说,还是比较复杂的,还好公司有linux大牛配合上我从各种技术网站博客吸收的微薄知识，从0开始">
<meta name="twitter:image" content="https://www.itweet.cn/screenshots/hardware-disk.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  <script id="baidu_analytics">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b75d841b3068f7782eac9af2c8c866e7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-154998721-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-154998721-1');
</script>


    <title> Hadoop平台架构--硬件篇 - WHOAMI </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">WHOAMI</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/atom.xml">
                            
                            
                                RSS
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Hadoop平台架构--硬件篇
        
      </h1>

      <time class="post-time">
          1月 26 2016
      </time>
    </header>



    
            <div class="post-content">
            <p>  还记得刚接触Hadoop的时候,还是1.x版本,硬是在自己的4GB内存上面弄了3个虚拟机<br>学习,条件有些艰苦,Hadoop测试集群搭建不需要太多考虑,随着毕业开始进入企业,在企业中实践Hadoop,特别是一定规模的集群,逐渐涉及到硬件资源,网络规划,操作系统,软件栈等一系列问题！对于一个没有经验的小白来说,还是比较复杂的,还好公司有linux大牛配合上我从各种技术网站博客吸收的微薄知识，从0开始搭建集群稳定运行2年多,接近年关,今晚我把这些问题简单梳理一下,写在Hadoop十周年纪念,希望对出建集群的同学有些许帮助！</p>
<h1 id="什么决定集群规模？"><a href="#什么决定集群规模？" class="headerlink" title="什么决定集群规模？"></a>什么决定集群规模？</h1><p>  Hadoop资源包括：存储和计算,对于计算资源其实初建集群很难评估,所以可以先忽略计算资源评估，单从存储指标来规划.首先找准这个方向，接下来就是和数据团队沟通收集数据量,每天数据增长率,数据存储周期,尽量多了解信息,存储周期是1个月,3个月,半年来确认数据量,从而计算存储,从存储出发规划集群是前期最合理的方向。</p>
<p>  比如：每天增长数据量为4T, 3倍冗余,存储3个月为周期,大概存储=4T<em>3</em>90天=1080T,这个基础上面需要乘一个系数,考虑给用户,磁盘计算,临时空间留一部分存储,未来数据增长趋势,分析结果存储周期占用空间,这些都是HDFS相关！在HDFS存储的基础上面,还需要考虑LinuxOS(Linux分区规划).评估完成之后，最重要的还是考虑企业的投入意愿和财力现状.这个系数需要综合考量.如何合理规划分区,使用目录规范,存储初步确定集群规模.规划非常合理而被用户不合理利用资源,那合理的规划就变得不合理了,有关合理存储规划请参考《<a href="https://www.itweet.cn/2016/01/25/Hadoop-Disk-Planning/" target="_blank" rel="noopener">Hadoop平台架构–存储篇</a>》 </p>
<h1 id="工作负载-amp-amp-软件栈"><a href="#工作负载-amp-amp-软件栈" class="headerlink" title="工作负载 &amp;&amp; 软件栈?"></a>工作负载 &amp;&amp; 软件栈?</h1><p>  几乎在很多场景,MapRdeuce或者说分布式架构,都会在IO受限,硬盘或者网络读取数据<br>遇到瓶颈.处理数据瓶颈CPU受限.大量的硬盘读写数据是海量数据分析常见情况！</p>
<ul>
<li><p>IO受限例子：</p>
<ul>
<li>索引</li>
<li>分组</li>
<li>数据倒入导出</li>
<li>数据移动和转换</li>
</ul>
</li>
<li><p>CPU受限例子：</p>
<ul>
<li>聚类/分类</li>
<li>复杂的文本挖掘</li>
<li>特征提取</li>
<li>用户画像</li>
<li>自然语言处理</li>
</ul>
<p>目前Hadoop发展为一个无所不包的数据平台,所以不仅仅是MapReudce使用,多种计算模型可插拔和Hadoop无缝结合,Hadoop2.x版本Yarn资源管理器,可以兼容多种技术模型；如：内存计算代表的saprk,impala,tez,drill,presto.磁盘计算代表的hive,mapreduce,pig. 对于一个异构集群,会同时存在多种计算模型！在硬件配置上面就需要高内存,大磁盘; Impala推荐最低配置128G内存,才能发挥优势；spark典型的CPU密集型,需要更多CPU和内存。Hive,MR磁盘计算,多磁盘读写比较频繁！当你在为集群硬件选型的时候，需要考虑的软件组件包括Apache HBase、Cloudera Impala、Presto Or Drill、Apache Phoenix和Apache spark。</p>
<ul>
<li><p>1、Hbase是一个可靠的列数据存储系统，它提供一致性、低延迟和随机读写。region的一些坑,在Hbase1.0+版本提供新的API，访问集群类似JDBC形式,增加了异步写入API，一主多从region, 解决region offline问题；<a href="https://www.itweet.cn/2016/01/09/Hbase-server-optimization/" target="_blank" rel="noopener">Hbase-Region-split-policy</a>！</p>
</li>
<li><p>2、Impala项目为Hadoop带来了可扩展的并行数据库技技术,使得用户可以向HDFS和HBase中存储的数据发起低延迟的SQL查询，而且不需要数据移动或转换。Cloudera开源;内存使用评估不合理,数据量太大,join性能低下！hive都跑完了,还没结束！</p>
</li>
<li><p>3、PrestoDb或者Drill,Presto让我们方便的查询Hive,Nosql(hbase,cassandra,redis),RDBMS(mysql,postgresql)；Facebook开源;有商业公司在支持;功能是把Hadoop和多种数据源联系起来,让Hadoop兼容更多数据源,实现无所不包的数据平台！一切看上去都是那么美好谁用谁知道…小声说一句木有写磁盘功能,内存不够直接报错,一部分节点失去联系，短时间使用不鸟了.</p>
</li>
<li><p>4、Drill和Presto非常类似可以支持SQL直接查询很多数据源：Hive,HDFS,Hbase,MongoDB,S3,RDBMS(Mysql,Oracle,postgresql,SQLServer)；MapR主推;把Hadoop和多种数据源联系起来,让Hdoop兼容更多数据源,实现无所不包的数据平台！</p>
</li>
<li><p>5、Hive提供稳定和可靠的SQL分析海量数据,也是最早的SQL on Hadoop解决方案！</p>
</li>
<li><p>6、Tez,HDP主推,可以替代Hive底层执行引擎MR,让hive拥有内存计算相当的性能！生产有使用过,可靠稳定,join有些时候不如Hive！</p>
</li>
<li><p>7、spark,对于这个框架,让人又爱又恨,主要用在机器学习和图计算吧！<br>SparkSQL做过一些性能测试,性能并没有外界宣称的那么牛X,生产环境也用过,<br>说多了都是泪啊,SQL模块投入力度比较小,也是最易用的吧,很多SQL on Hadoop方案都比它做的好,所以呵呵..！spark 1.6 新版Dataset API更好的内存管理,钨丝计划等提升性能！Spark宣传做的非常好；我们使用下来SQL性能不如其他方案,稳定性不够好！executor假死,甚至退出无法恢复,稳定性还不如Tez吧！当然也可能<br>是我们技术能力不够吧！用来做机器学习,图计算,通过API开发数据清洗入库Hbase<br>提供查询！替代MR做开发是一种选择吧！SQL模块Join性能低下,单表查询性能ok！</p>
</li>
<li><p>8、Phoenix,SQL-on-Hbase解决方案！这是除了Hive/Impala on Hbase比较好的方案,Phoenix底层是调用Hbase API实现查询,所以能用到Hbase的优化器,社区跟进Hbase也很<br>快,是一个不错的方案！</p>
</li>
</ul>
<p>SQL on Hadoop我个人花费了大量精力做性能测试,可能个人技术能力有限无法做到全面<br>，目前对于亿级表,足够大内存，全方位比较 Imapla &gt; PrestoDb &gt; SparkSQL &gt; Tez &gt; Drill &gt; Hive。当然比如20-30亿单表查询检索PrestoDb,SparkSql,Hive能很快完成,而Impala写了磁盘,或某些节点压力太大崩溃了,性能急剧下降！针对这些SQL,NOSQL产品我们技术选型的时候做过tpch,tpcds,ycbs,业务场景等性能测试！目前<br>市面上开源的SQL-on-Hadoop基本没一个能跑全的！使用也很多坑,谁用谁知道…<br>有关集群存储格式如何选择请参考《<a href="https://www.itweet.cn/2016/01/25/Hadoop-Disk-Planning/" target="_blank" rel="noopener">Hadoop平台架构–存储篇</a>》 </p>
</li>
</ul>
<blockquote>
<p>我们下面说的硬件选型都是基于异构集群！</p>
</blockquote>
<h1 id="硬件配置如何选择？"><a href="#硬件配置如何选择？" class="headerlink" title="硬件配置如何选择？"></a>硬件配置如何选择？</h1><p>  硬件的选择,要高配还是低配？<br>  确定节点规模,cpu、内存、磁盘配比？</p>
<ul>
<li><p>1、节点规模按照,数据增长率+浮动系数确定！弹性扩展节点,容灾,HA高可靠方面！<br>单个节点故障，对于20节点集群,计算能力失去20%,对于100节点的集群计算能力失去<br>1%。如果没有自动化,监控管理也是一大成本！</p>
</li>
<li><p>2、初建立集群建议考虑主流配置,平衡集群资源,存储不够,调整搞压缩比例算法,拿<br>CPU换存储；当CPU不足，以网络宽带换CPU。集群拥有多个机架，考虑Hdoop的机架感知<br>功能的配置！</p>
</li>
<li><p>3、软件层面的资源管理，比如所以计算框架都在Yarn申请资源,需要分配资源池等.有关各种软件层面的优化请参考相关yarn资源调优内容！</p>
</li>
<li><p>4、硬件配置参考</p>
<ul>
<li><p>异构集群<br><img src="https://www.itweet.cn/screenshots/hardware-disk.png" alt></p>
</li>
<li><p>小集群,次多增加硬件,规格不一致,需要考虑资源利用率问题？<br><img src="https://www.itweet.cn/screenshots/hardware-disk-2.png" alt></p>
</li>
</ul>
<p><code>注意：1块盘   3T 理论大小应为   3*1024G   =3096G 实际大小3000G，
而我们实际计算时使用的是1024.</code></p>
</li>
</ul>
<h1 id="Hadoop版本如何选择？"><a href="#Hadoop版本如何选择？" class="headerlink" title="Hadoop版本如何选择？"></a>Hadoop版本如何选择？</h1><p>   在Hadoop的发行版包括：Apache hadoop、Cloudera cdh，Hortonworks HDP 。后两者是商业团队在原生apache hadoop之上做一些优化和调整,目前我们<br>主要选择Cloudera Hadoop发行版,如果公司有研发能力能够同时跟进几条Hdoop<br>家族软件发展，并且能fix bug，使用更多新功能新特性，可以考虑Apache Hdoop版本。<br>Cloudera CDH版本,基于Cloudrea强大的研发能力,能很快修复bug,更加可靠稳定，一套<br>好用ClouderaManager监控方案！如果你选择HDP版本，其实也和选择Apache版本比较接近了,HDP版本有商业公司支持,但是基本就是把开源的Hadoop家族做了一个安装包,号称是基于完全开源的软件栈构建，而权限控制模块是不开源的,和自己的基于完全开源<br>口号有些背道而驰；选择商业发行版,在搭建基础环境上面少浪费一些时间,可以多把时<br>间花在应用层面，你说你搭建个基础集群环境都弄几天，使用一个安装包,几个小时<br>就完成就专注于应用层面！甚至可以做出一键批量安装,从硬件上架通电之后,linux系统安装完成之后,集群就可以使用了！完全的自动化！配合好用的监控图标<br>降低运维成本！<br>  当然,选择商业发行版,可定制性就低一些,重大bug需要等待新版本的发布.而且<br>某些Hadoop软件栈由于竞争或者某些利益关系,而在发行版中被砍掉,比如在CDH<br>版本中SparkSQL是被砍掉的,虽然两家公司在合作,也有hive on spark项目,但是<br>相对来说是有点抢Impala生意的！我们的做法是自己编译spark版本在CDH集群中<br>独立模式部署一套Spark集群,但是比如on Yarn模式是无法使用的！SparkSQL独立<br>模式和CDH其他组件配置使用时没有任何问题。比如资源管理就不能都统一在Yarn<br>管理！对于维护和使用都造成一定的麻烦！</p>
<h1 id="节点该如何分配？"><a href="#节点该如何分配？" class="headerlink" title="节点该如何分配？"></a>节点该如何分配？</h1><p> Hadoop包括两类节点：<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">  Master： CPU：16CPU*4核 ;内存：128G-512G; HA 需要两台Namenode,配置一致！</span><br><span class="line"></span><br><span class="line">  Slave:   CPU：8CPU*4核-16CPU*4核;内存：16G-24G128G-256G;配置最好一致,如果不一致,资源分配需要着重考虑！</span><br><span class="line"></span><br><span class="line">  LinuxOS: redhat 6.3 or CentOS 6.6,NameNode节点存储区做RAID1！Datanode节点磁盘JBOD安装，无RAID。Linux系统盘做RAID1</span><br><span class="line"></span><br><span class="line">  硬件配置如果存在一定的差异需要考虑资源利用率问题！特别注意有单点的问题的统一放到一台主机！</span><br><span class="line"></span><br><span class="line">  集中式Master，将SPOF单点集中到一起:Namenode HA,HMaster HA,Spark Master,</span><br><span class="line">  JobTracker/ResourceManager HA ,Hive Metastore,HiveServer2,Impala StateStore,</span><br><span class="line">  Catalog Server,impala-LLAMA HA,Oozie,Sentry,Hue</span><br><span class="line"></span><br><span class="line">  Slave,例如：Impalad,TaskTracker/Nodemanager,RegionServer,spark worker</span><br><span class="line"></span><br><span class="line">  计算资源统一交给yarn分配,所有的作业分组，按部门，不同的作业类型,划分不同</span><br><span class="line">的资源池，每个部门和作业类型分组，放入不同的资源池处理.有关资源分配内容,</span><br><span class="line">请参考《Yarn资源分配性能调优》，Map slot,Reduce slot这些值怎么来的,Yarn的资源池</span><br><span class="line">,Hadoop-2.6新功能,Hadoop YARN新特性—label based scheduling,基于标签的调度策略！</span><br><span class="line">怎么优化来提升性能，怎么合理利用资源！请参考更多相关文章！</span><br><span class="line">如果你对初建Hadoop集群前期硬件配置,版本选择等还有疑问欢迎讨论！</span><br></pre></td></tr></table></figure></p>
<p><a href="https://www.itweet.cn/2015/07/24/yarn-resources-manager-allocation/" target="_blank" rel="noopener">Yarn资源分配性能调优</a></p>
<h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p> 购买合适的硬件，对于一个Hapdoop群集而言，需要性能测试和细心的计划，从而全面理解工作负荷。然而，Hadoop群集通常是一个形态变化的系统， 而Cloudera建议，在开始的时候，使用负载均衡的技术文档来部署启动的硬件。重要的是，记住，当使用多种体系组件的时候，资源的使用将会是多样的, 而专注与资源管理将会是你成功的关键。</p>
<p>推荐技术网站：<br>    <a href="http://www.cloudera.com/content/www/en-us/documentation.html" target="_blank" rel="noopener">http://www.cloudera.com/content/www/en-us/documentation.html</a><br>    <a href="http://blog.cloudera.com/" target="_blank" rel="noopener">http://blog.cloudera.com/</a><br>    <a href="http://docs.hortonworks.com/" target="_blank" rel="noopener">http://docs.hortonworks.com/</a><br>    <a href="http://databricks.com/blog" target="_blank" rel="noopener">http://databricks.com/blog</a></p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/hadoop/">hadoop</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/03/10/sqoop-自动化脚本/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">sqoop 自动化脚本</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2016/01/25/Hadoop平台架构--存储篇/">
        <span class="next-text nav-default">Hadoop平台架构--存储篇</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
    <div style="text-align:center;">
        <button class="btn" id="load-disqus" onclick="disqus.load();">加载 Disqus 评论</button>
    </div>
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2023
    <span class="footer-author">Xu Jiang.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/realXuJiang/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    

<script type="text/javascript">
  var disqus_shortname = 'itweet-cn';
  var disqus_identifier = '2016/01/26/Hadoop-par1/';

  var disqus_title = "Hadoop平台架构--硬件篇";


  var disqus = {
    load : function disqus(){
        if(typeof DISQUS !== 'object') {
          (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
          }());
          $('#load-disqus').remove(); ///加载后移除按钮
        }
    }
  }

  
    var disqus_config = function () {
        this.page.url = disqus_url;
        this.page.identifier = disqus_identifier;
        this.page.title = disqus_title;
    };
  

</script>


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
