<!DOCTYPE html>
<html lang="zh-CN">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="Hive on Spark 整合测试">




  <meta name="keywords" content="SQL,">





  <link rel="alternate" href="/atom.xml" title="WHOAMI">




  <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/itweet/itweet.github.io/master/favicon.ico?v=1.1">



<link rel="canonical" href="http://itweet.github.io/2016/06/27/Hive-on-Spark-整合测试/">


<meta name="description" content="根据官方给出的文档，进行编译打包，需要注意的是，”Hive on Spark is available from Hive 1.1+ onward,It is still under active development in “spark” and “spark2” branches, and is periodically merged into the “master” branch for">
<meta name="keywords" content="SQL">
<meta property="og:type" content="article">
<meta property="og:title" content="Hive on Spark 整合测试">
<meta property="og:url" content="http://itweet.github.io/2016/06/27/Hive-on-Spark-整合测试/index.html">
<meta property="og:site_name" content="WHOAMI">
<meta property="og:description" content="根据官方给出的文档，进行编译打包，需要注意的是，”Hive on Spark is available from Hive 1.1+ onward,It is still under active development in “spark” and “spark2” branches, and is periodically merged into the “master” branch for">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-12-25T14:39:06.129Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hive on Spark 整合测试">
<meta name="twitter:description" content="根据官方给出的文档，进行编译打包，需要注意的是，”Hive on Spark is available from Hive 1.1+ onward,It is still under active development in “spark” and “spark2” branches, and is periodically merged into the “master” branch for">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  <script id="baidu_analytics">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b75d841b3068f7782eac9af2c8c866e7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-154998721-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-154998721-1');
</script>


    <title> Hive on Spark 整合测试 - WHOAMI </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">WHOAMI</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/atom.xml">
                            
                            
                                RSS
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Hive on Spark 整合测试
        
      </h1>

      <time class="post-time">
          6月 27 2016
      </time>
    </header>



    
            <div class="post-content">
            <p>根据官方给出的文档，进行编译打包，需要注意的是，”Hive on Spark is available from Hive 1.1+ onward,It is still under active development in “spark” and “spark2” branches, and is periodically merged into the “master” branch for Hive.”</p>
<ul>
<li>YARN Mode: <a href="http://spark.apache.org/docs/latest/running-on-yarn.html" target="_blank" rel="noopener">http://spark.apache.org/docs/latest/running-on-yarn.html</a> </li>
<li>Standalone Mode: <a href="https://spark.apache.org/docs/latest/spark-standalone.html" target="_blank" rel="noopener">https://spark.apache.org/docs/latest/spark-standalone.html</a></li>
</ul>
<h1 id="build-package-with［hive-on-spark"><a href="#build-package-with［hive-on-spark" class="headerlink" title="build package with［hive on spark]"></a>build package with［hive on spark]</h1><p><a href="https://cwiki.apache.org/confluence/display/Hive/Hive+on+Spark%3A+Getting+Started#HiveonSpark:GettingStarted-ConfiguringHive" target="_blank" rel="noopener">Hive on Spark</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ wget https://dist.apache.org/repos/dist/release/spark/spark-1.6.2/spark-1.6.2.tgz</span><br><span class="line">$ export MAVEN_OPTS=&quot;-Xmx2g -XX:MaxPermSize=512M -XX:ReservedCodeCacheSize=512m&quot;</span><br></pre></td></tr></table></figure></p>
<p>通过执行如下命令，可以完成打包，注意不要加hive参数，spark的包必须时没有集成过hive的，所以需要自己手动编译，官方提供的都是集成hive的：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">./make-distribution.sh --name &quot;hadoop2-without-hive&quot; --tgz &quot;-Pyarn,hadoop-provided,hadoop-2.6,parquet-provided&quot;</span><br><span class="line"></span><br><span class="line">[INFO] Replacing original artifact with shaded artifact.</span><br><span class="line">[INFO] Replacing /data/spark-1.6.2/external/kafka-assembly/target/spark-streaming-kafka-assembly_2.10-1.6.2.jar with /data/spark-1.6.2/external/kafka-assembly/target/spark-streaming-kafka-assembly_2.10-1.6.2-shaded.jar</span><br><span class="line">[INFO] Dependency-reduced POM written at: /data/spark-1.6.2/external/kafka-assembly/dependency-reduced-pom.xml</span><br><span class="line">[INFO] Dependency-reduced POM written at: /data/spark-1.6.2/external/kafka-assembly/dependency-reduced-pom.xml</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-source-plugin:2.4:jar-no-fork (create-source-jar) @ spark-streaming-kafka-assembly_2.10 ---</span><br><span class="line">[INFO] Building jar: /data/spark-1.6.2/external/kafka-assembly/target/spark-streaming-kafka-assembly_2.10-1.6.2-sources.jar</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-source-plugin:2.4:test-jar-no-fork (create-source-jar) @ spark-streaming-kafka-assembly_2.10 ---</span><br><span class="line">[INFO] Building jar: /data/spark-1.6.2/external/kafka-assembly/target/spark-streaming-kafka-assembly_2.10-1.6.2-test-sources.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Reactor Summary:</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] Spark Project Parent POM ........................... SUCCESS [ 11.410 s]</span><br><span class="line">[INFO] Spark Project Test Tags ............................ SUCCESS [  6.995 s]</span><br><span class="line">[INFO] Spark Project Launcher ............................. SUCCESS [01:18 min]</span><br><span class="line">[INFO] Spark Project Networking ........................... SUCCESS [ 30.344 s]</span><br><span class="line">[INFO] Spark Project Shuffle Streaming Service ............ SUCCESS [ 15.242 s]</span><br><span class="line">[INFO] Spark Project Unsafe ............................... SUCCESS [01:11 min]</span><br><span class="line">[INFO] Spark Project Core ................................. SUCCESS [11:11 min]</span><br><span class="line">[INFO] Spark Project Bagel ................................ SUCCESS [ 12.017 s]</span><br><span class="line">[INFO] Spark Project GraphX ............................... SUCCESS [ 50.978 s]</span><br><span class="line">[INFO] Spark Project Streaming ............................ SUCCESS [01:24 min]</span><br><span class="line">[INFO] Spark Project Catalyst ............................. SUCCESS [01:24 min]</span><br><span class="line">[INFO] Spark Project SQL .................................. SUCCESS [01:39 min]</span><br><span class="line">[INFO] Spark Project ML Library ........................... SUCCESS [01:36 min]</span><br><span class="line">[INFO] Spark Project Tools ................................ SUCCESS [  3.208 s]</span><br><span class="line">[INFO] Spark Project Hive ................................. SUCCESS [01:00 min]</span><br><span class="line">[INFO] Spark Project Docker Integration Tests ............. SUCCESS [  4.042 s]</span><br><span class="line">[INFO] Spark Project REPL ................................. SUCCESS [ 12.562 s]</span><br><span class="line">[INFO] Spark Project YARN Shuffle Service ................. SUCCESS [  8.056 s]</span><br><span class="line">[INFO] Spark Project YARN ................................. SUCCESS [ 41.988 s]</span><br><span class="line">[INFO] Spark Project Assembly ............................. SUCCESS [01:08 min]</span><br><span class="line">[INFO] Spark Project External Twitter ..................... SUCCESS [ 10.449 s]</span><br><span class="line">[INFO] Spark Project External Flume Sink .................. SUCCESS [ 13.694 s]</span><br><span class="line">[INFO] Spark Project External Flume ....................... SUCCESS [ 14.953 s]</span><br><span class="line">[INFO] Spark Project External Flume Assembly .............. SUCCESS [  5.518 s]</span><br><span class="line">[INFO] Spark Project External MQTT ........................ SUCCESS [ 53.497 s]</span><br><span class="line">[INFO] Spark Project External MQTT Assembly ............... SUCCESS [ 51.715 s]</span><br><span class="line">[INFO] Spark Project External ZeroMQ ...................... SUCCESS [ 27.235 s]</span><br><span class="line">[INFO] Spark Project External Kafka ....................... SUCCESS [ 15.628 s]</span><br><span class="line">[INFO] Spark Project Examples ............................. SUCCESS [02:13 min]</span><br><span class="line">[INFO] Spark Project External Kafka Assembly .............. SUCCESS [ 11.596 s]</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 30:52 min</span><br><span class="line">[INFO] Finished at: 2016-06-27T18:11:33+08:00</span><br><span class="line">[INFO] Final Memory: 104M/1071M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">+ rm -rf /data/spark-1.6.2/dist</span><br><span class="line">+ mkdir -p /data/spark-1.6.2/dist/lib</span><br><span class="line">+ echo &apos;Spark 1.6.2 built for Hadoop 2.6.0&apos;</span><br><span class="line">+ echo &apos;Build flags: -Pyarn,hadoop-provided,hadoop-2.6,parquet-provided&apos;</span><br><span class="line">+ cp /data/spark-1.6.2/assembly/target/scala-2.10/spark-assembly-1.6.2-hadoop2.6.0.jar /data/spark-1.6.2/dist/lib/</span><br><span class="line">+ cp /data/spark-1.6.2/examples/target/scala-2.10/spark-examples-1.6.2-hadoop2.6.0.jar /data/spark-1.6.2/dist/lib/</span><br><span class="line">+ cp /data/spark-1.6.2/network/yarn/target/scala-2.10/spark-1.6.2-yarn-shuffle.jar /data/spark-1.6.2/dist/lib/</span><br><span class="line">+ mkdir -p /data/spark-1.6.2/dist/examples/src/main</span><br><span class="line">+ cp -r /data/spark-1.6.2/examples/src/main /data/spark-1.6.2/dist/examples/src/</span><br><span class="line">+ &apos;[&apos; 0 == 1 &apos;]&apos;</span><br><span class="line">+ cp /data/spark-1.6.2/LICENSE /data/spark-1.6.2/dist</span><br><span class="line">+ cp -r /data/spark-1.6.2/licenses /data/spark-1.6.2/dist</span><br><span class="line">+ cp /data/spark-1.6.2/NOTICE /data/spark-1.6.2/dist</span><br><span class="line">+ &apos;[&apos; -e /data/spark-1.6.2/CHANGES.txt &apos;]&apos;</span><br><span class="line">+ cp /data/spark-1.6.2/CHANGES.txt /data/spark-1.6.2/dist</span><br><span class="line">+ cp -r /data/spark-1.6.2/data /data/spark-1.6.2/dist</span><br><span class="line">+ mkdir /data/spark-1.6.2/dist/conf</span><br><span class="line">+ cp /data/spark-1.6.2/conf/docker.properties.template /data/spark-1.6.2/conf/fairscheduler.xml.template /data/spark-1.6.2/conf/log4j.properties.template /data/spark-1.6.2/conf/metrics.properties.template /data/spark-1.6.2/conf/slaves.template /data/spark-1.6.2/conf/spark-defaults.conf.template /data/spark-1.6.2/conf/spark-env.sh.template /data/spark-1.6.2/dist/conf</span><br><span class="line">+ cp /data/spark-1.6.2/README.md /data/spark-1.6.2/dist</span><br><span class="line">+ cp -r /data/spark-1.6.2/bin /data/spark-1.6.2/dist</span><br><span class="line">+ cp -r /data/spark-1.6.2/python /data/spark-1.6.2/dist</span><br><span class="line">+ cp -r /data/spark-1.6.2/sbin /data/spark-1.6.2/dist</span><br><span class="line">+ cp -r /data/spark-1.6.2/ec2 /data/spark-1.6.2/dist</span><br><span class="line">+ &apos;[&apos; -d /data/spark-1.6.2/R/lib/SparkR &apos;]&apos;</span><br><span class="line">+ &apos;[&apos; false == true &apos;]&apos;</span><br><span class="line">+ &apos;[&apos; true == true &apos;]&apos;</span><br><span class="line">+ TARDIR_NAME=spark-1.6.2-bin-hadoop2-without-hive</span><br><span class="line">+ TARDIR=/data/spark-1.6.2/spark-1.6.2-bin-hadoop2-without-hive</span><br><span class="line">+ rm -rf /data/spark-1.6.2/spark-1.6.2-bin-hadoop2-without-hive</span><br><span class="line">+ cp -r /data/spark-1.6.2/dist /data/spark-1.6.2/spark-1.6.2-bin-hadoop2-without-hive</span><br><span class="line">+ tar czf spark-1.6.2-bin-hadoop2-without-hive.tgz -C /data/spark-1.6.2 spark-1.6.2-bin-hadoop2-without-hive</span><br><span class="line">+ rm -rf /data/spark-1.6.2/spark-1.6.2-bin-hadoop2-without-hive</span><br></pre></td></tr></table></figure></p>
<h1 id="required"><a href="#required" class="headerlink" title="required"></a>required</h1><p> <strong> hive-2.1.0支持spark-1.6.0 </strong></p>
<h1 id="Configuring-Hive"><a href="#Configuring-Hive" class="headerlink" title="Configuring Hive"></a>Configuring Hive</h1><p>1、环境变量中配置spark_home<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-server-1 cloud]# echo $SPARK_HOME</span><br><span class="line">/opt/cloud/hive-on-spark</span><br></pre></td></tr></table></figure></p>
<p>2、进入hive-cli命令行，使用set的方式设置以下参数，也可在hive-site.xml中配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">set spark.home = /opt/cloud/hive-on-spark;</span><br><span class="line">add jar /opt/cloud/hive-on-spark/lib/spark-assembly-1.6.2-hadoop2.6.0.jar;</span><br><span class="line">set spark.master=yarn-client;  //默认即为yarn-client模式</span><br><span class="line">set hive.execution.engine=spark;</span><br><span class="line">set spark.eventLog.enabled=true;</span><br><span class="line">set spark.eventLog.dir=hdfs://bigdata-server-1:8020/tmp/sparkeventlog;</span><br><span class="line">set spark.executor.memory=1g; </span><br><span class="line">set spark.executor.instances=10;  //executor数量</span><br><span class="line">set spark.driver.memory=1g; </span><br><span class="line">set spark.serializer=org.apache.spark.serializer.KryoSerializer;</span><br></pre></td></tr></table></figure></p>
<p>3、执行sql测试spark引擎<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/SQL/">SQL</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/07/02/Hadoop-Native-Libraries-Guide/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Hadoop Native Libraries Guide</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2016/06/16/openstack-issue/">
        <span class="next-text nav-default">openstack-issue</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
    <div style="text-align:center;">
        <button class="btn" id="load-disqus" onclick="disqus.load();">加载 Disqus 评论</button>
    </div>
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2023
    <span class="footer-author">Xu Jiang.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/realXuJiang/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    

<script type="text/javascript">
  var disqus_shortname = 'itweet-cn';
  var disqus_identifier = '2016/06/27/Hive-on-Spark-整合测试/';

  var disqus_title = "Hive on Spark 整合测试";


  var disqus = {
    load : function disqus(){
        if(typeof DISQUS !== 'object') {
          (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
          }());
          $('#load-disqus').remove(); ///加载后移除按钮
        }
    }
  }

  
    var disqus_config = function () {
        this.page.url = disqus_url;
        this.page.identifier = disqus_identifier;
        this.page.title = disqus_title;
    };
  

</script>


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
