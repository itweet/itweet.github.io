<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="openstack-issue">




  <meta name="keywords" content="openstack,">





  <link rel="alternate" href="/atom.xml" title="WHOAMI">




  <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/itweet/itweet.github.io/master/favicon.ico?v=1.1">



<link rel="canonical" href="http://itweet.github.io/2016/06/16/openstack-issue/">


<meta name="description" content="openstack 生产环境问题纪录。 1、horizon “router_gateway  DOWN”horizon 页面路由显示信息 “router_gateway   DOWN”，路由－》接口－》外部网关－》状态：停止 ｜ 默认：创建  初步认定是openstack的bug，虽然是down状态但是不影响使用  排查过程  1.1 页面看到外部网关“停止状态”的固定IP地址，通过如下命令过滤出">
<meta name="keywords" content="openstack">
<meta property="og:type" content="article">
<meta property="og:title" content="openstack-issue">
<meta property="og:url" content="http://itweet.github.io/2016/06/16/openstack-issue/index.html">
<meta property="og:site_name" content="WHOAMI">
<meta property="og:description" content="openstack 生产环境问题纪录。 1、horizon “router_gateway  DOWN”horizon 页面路由显示信息 “router_gateway   DOWN”，路由－》接口－》外部网关－》状态：停止 ｜ 默认：创建  初步认定是openstack的bug，虽然是down状态但是不影响使用  排查过程  1.1 页面看到外部网关“停止状态”的固定IP地址，通过如下命令过滤出">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-09-25T16:03:06.059Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="openstack-issue">
<meta name="twitter:description" content="openstack 生产环境问题纪录。 1、horizon “router_gateway  DOWN”horizon 页面路由显示信息 “router_gateway   DOWN”，路由－》接口－》外部网关－》状态：停止 ｜ 默认：创建  初步认定是openstack的bug，虽然是down状态但是不影响使用  排查过程  1.1 页面看到外部网关“停止状态”的固定IP地址，通过如下命令过滤出">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> openstack-issue - WHOAMI </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">WHOAMI</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/atom.xml">
                            
                            
                                RSS
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          openstack-issue
        
      </h1>

      <time class="post-time">
          6月 16 2016
      </time>
    </header>



    
            <div class="post-content">
            <p>openstack 生产环境问题纪录。</p>
<h1 id="1、horizon-“router-gateway-DOWN”"><a href="#1、horizon-“router-gateway-DOWN”" class="headerlink" title="1、horizon “router_gateway  DOWN”"></a>1、horizon “router_gateway  DOWN”</h1><p><code>horizon 页面路由显示信息 “router_gateway   DOWN”，路由－》接口－》外部网关－》状态：停止 ｜ 默认：创建</code></p>
<ul>
<li><p>初步认定是openstack的bug，虽然是down状态但是不影响使用</p>
</li>
<li><p>排查过程</p>
<ul>
<li>1.1 页面看到外部网关“停止状态”的固定IP地址，通过如下命令过滤出来，最后获取状态看到“down”<br>[root@controller ~(keystone_admin)]# <code>neutron port-list|grep 192.168.2.100</code><br>| 857833bb-ae82-40c2-a6db-498b71660f17 |      | fa:16:3e:20:b8:b2 | {“subnet_id”: “e380ee29-c00f-485b-9ab2-7da3466cb9e1”, “ip_address”: “192.168.2.100”} |</li>
</ul>
</li>
</ul>
<p>[root@controller ~(keystone_admin)]# <code>neutron port-show</code>857833bb-ae82-40c2-a6db-498b71660f17|grep status<br>| status                | <code>DOWN</code>                                        </p>
<p>[root@controller ~(keystone_admin)]# <code>neutron router-show router|grep status</code><br>| status                | ACTIVE                                               </p>
<p>[root@controller ~(keystone_admin)]#  <code>neutron help | grep route</code><br>  l3-agent-list-hosting-router      List L3 agents hosting a router.<br>  l3-agent-router-add               Add a router to a L3 agent.<br>  l3-agent-router-remove            Remove a router from a L3 agent.<br>  net-gateway-connect               Add an internal network interface to a router.<br>  router-create                     Create a router for a given tenant.<br>  router-delete                     Delete a given router.<br>  router-gateway-clear              Remove an external network gateway from a router.<br>  router-gateway-set                Set the external network gateway for a router.<br>  router-interface-add              Add an internal network interface to a router.<br>  router-interface-delete           Remove an internal network interface from a router.<br>  router-list                       List routers that belong to a given tenant.<br>  router-list-on-l3-agent           List the routers on a L3 agent.<br>  router-port-list                  List ports that belong to a given tenant, with specified router.<br>  router-show                       Show information of a given router.<br>  router-update                     Update router’s information.</p>
<h1 id="2、修改主机配置大小，导致数据迁移失败。"><a href="#2、修改主机配置大小，导致数据迁移失败。" class="headerlink" title="2、修改主机配置大小，导致数据迁移失败。"></a>2、修改主机配置大小，导致数据迁移失败。</h1><p> openstack 故障：Authentication required 500，页面看到是调整大小的时候报错。</p>
<p> 修改主机大小，会新建立一个主机，把旧的数据迁移到新的主机，在完成最后的合并工作，但是由于物理机压力太大，导致迁移失败。后天看到有两个虚拟机，处于关闭状态。</p>
<ul>
<li><p>手动重启主机实例，去前台的vnc客户端看到，主机启动了，没有任何问题，正常可以使用，就前台有个错误状态让人不爽。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@openstack-controller ~]# virsh list --all </span><br><span class="line"> Id    Name                           State</span><br><span class="line">----------------------------------------------------</span><br><span class="line"> 136   instance-0000003a              running</span><br><span class="line"> -     instance-0000003c              shut off</span><br><span class="line"> -     instance-00000079              shut off</span><br><span class="line"></span><br><span class="line">[root@controller ~]# virsh start instance-0000003c </span><br><span class="line">Domain instance-0000003c started</span><br><span class="line"></span><br><span class="line">[root@openstack-controller ~]# virsh list --all              </span><br><span class="line"> Id    Name                           State</span><br><span class="line">----------------------------------------------------</span><br><span class="line"> 136   instance-0000003a              running</span><br><span class="line"> 137   instance-0000003c              running</span><br><span class="line"> -     instance-00000079              shut off</span><br></pre></td></tr></table></figure>
</li>
<li><p>虽然云主机正常使用，但是前台无法在管理到此云主机,想办法把数据和服务先迁移走。然后单独修改数据库状态，使它正常接收管理，恢复正常使用。</p>
</li>
</ul>
<h1 id="3、虚拟机一直处于删除状态－前台卡死－发现前后端数据不一致"><a href="#3、虚拟机一直处于删除状态－前台卡死－发现前后端数据不一致" class="headerlink" title="3、虚拟机一直处于删除状态－前台卡死－发现前后端数据不一致"></a>3、虚拟机一直处于删除状态－前台卡死－发现前后端数据不一致</h1><p>  检测发现，虚拟机一直处于删除状态，无法释放。</p>
<p>通过source keystone_admin，进入管理员权限，查看虚拟机状态，发现处于deleteing状态。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@controller ~(keystone_admin)]# nova list|grep deleting</span><br><span class="line">| c6eb16d4-d607-4c98-b329-9defc4ba7586 | RedHadoop03          | ACTIVE | deleting   | Running     | private=172.16.1.242                |</span><br><span class="line">| 227a1b8b-93cf-4e55-af73-db0d60e80a69 | RedHadoop04          | ACTIVE | deleting   | Running     | private=172.16.1.243                |</span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>解决方法，首先reset-state这台虚拟机，然后执行<code>nova delte 虚拟机ID</code>进行删除。</p>
</blockquote>
<ul>
<li><p>reset 虚拟机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@controller nova(keystone_admin)]# nova reset-state --active c6eb16d4-d607-4c98-b329-9defc4ba7586</span><br><span class="line">Reset state for server c6eb16d4-d607-4c98-b329-9defc4ba7586 succeeded; new state is active</span><br></pre></td></tr></table></figure>
</li>
<li><p>查看虚拟机状态</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">[root@controller nova(keystone_admin)]# nova show c6eb16d4-d607-4c98-b329-9defc4ba7586</span><br><span class="line">+--------------------------------------+----------------------------------------------------------+</span><br><span class="line">| Property                             | Value                                                    |</span><br><span class="line">+--------------------------------------+----------------------------------------------------------+</span><br><span class="line">| OS-DCF:diskConfig                    | MANUAL                                                   |</span><br><span class="line">| OS-EXT-AZ:availability_zone          | nova                                                     |</span><br><span class="line">| OS-EXT-SRV-ATTR:host                 | compute1                                                 |</span><br><span class="line">| OS-EXT-SRV-ATTR:hypervisor_hostname  | compute1                                                 |</span><br><span class="line">| OS-EXT-SRV-ATTR:instance_name        | instance-000001ea                                        |</span><br><span class="line">| OS-EXT-STS:power_state               | 1                                                        |</span><br><span class="line">| OS-EXT-STS:task_state                | -                                                        |</span><br><span class="line">| OS-EXT-STS:vm_state                  | active                                                   |</span><br><span class="line">| OS-SRV-USG:launched_at               | 2016-07-25T07:51:36.000000                               |</span><br><span class="line">| OS-SRV-USG:terminated_at             | -                                                        |</span><br><span class="line">| accessIPv4                           |                                                          |</span><br><span class="line">| accessIPv6                           |                                                          |</span><br><span class="line">| config_drive                         |                                                          |</span><br><span class="line">| created                              | 2016-07-25T07:50:57Z                                     |</span><br><span class="line">| flavor                               | m1.xlarge (5)                                            |</span><br><span class="line">| hostId                               | 02a55d5ba7a2ec4a8af2d59c8267befc2378810113c2e6532fe0417a |</span><br><span class="line">| id                                   | c6eb16d4-d607-4c98-b329-9defc4ba7586                     |</span><br><span class="line">| image                                | demo (a304281c-7524-444e-ab39-29a9658b8944)              |</span><br><span class="line">| key_name                             | jin                                                      |</span><br><span class="line">| metadata                             | &#123;&#125;                                                       |</span><br><span class="line">| name                                 | RedHadoop03                                              |</span><br><span class="line">| os-extended-volumes:volumes_attached | []                                                       |</span><br><span class="line">| progress                             | 0                                                        |</span><br><span class="line">| status                               | ACTIVE                                                   |</span><br><span class="line">| tenant_id                            | d62eac96a5294336b1f508b5757088f6                         |</span><br><span class="line">| updated                              | 2016-07-26T08:55:54Z                                     |</span><br><span class="line">| user_id                              | b113bbc4934e4a71882206e516f2931e                         |</span><br><span class="line">+--------------------------------------+----------------------------------------------------------+</span><br></pre></td></tr></table></figure>
</li>
<li><p>删除虚拟机</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@controller nova(keystone_admin)]# nova delete c6eb16d4-d607-4c98-b329-9defc4ba7586</span><br><span class="line">Request to delete server c6eb16d4-d607-4c98-b329-9defc4ba7586 has been accepted.</span><br></pre></td></tr></table></figure>
</li>
<li><p>可通过<code>virsh list --all</code>命令查看是否删除干净，在配合<code>nova list</code>命令排查，查看是否还有一直处于删除状态的云主机。</p>
</li>
</ul>
<h1 id="3-云硬盘error、error-deleting、deleting状态"><a href="#3-云硬盘error、error-deleting、deleting状态" class="headerlink" title="3. 云硬盘error、error deleting、deleting状态"></a>3. 云硬盘error、error deleting、deleting状态</h1><p>起因是因为，机房断电了，重启之后，openstack集群其中有一台服务器启动后，网线未成功连接，导致此主机IP无法连接；而在这个时候，我并没有发现有一台服务器未加入集群，删除了一个快底层未glusterfs集群的云硬盘，接下来就出现了一直处于删除状态！</p>
<p>通过cinder命令查看云硬盘状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@openstack-controller ~(keystone_openstack-cloud)]# cinder list</span><br><span class="line">+--------------------------------------+----------------+----------------------------+------+-------------+----------+--------------------------------------+</span><br><span class="line">|                  ID                  |     Status     |            Name            | Size | Volume Type | Bootable |             Attached to              |</span><br><span class="line">+--------------------------------------+----------------+----------------------------+------+-------------+----------+--------------------------------------+</span><br><span class="line">| 11cb3510-533e-4db4-9999-ff2c7b72695a |     error      |   x86-build-glusterfs-1    | 100  |  GlusterFS  |   true   | cbc4f7ab-c167-4478-9982-64909f55e52e |</span><br><span class="line">| 3d07bbcd-c648-4bda-a0ee-96b9877b7a4b |     in-use     | gitlib-server-glusterfs-1  | 1000 |  GlusterFS  |  false   | b232560d-af7a-47f0-80c6-f708b9bda45e |</span><br><span class="line">| 751b6804-ce57-48d1-bbce-c0b9d4d10a97 | error_deleting | rancher-server-glusterfs-1 |  20  |  GlusterFS  |  false   |                                      |</span><br><span class="line">+--------------------------------------+----------------+----------------------------+------+-------------+----------+--------------------------------------+</span><br></pre></td></tr></table></figure></p>
<p>登录数据库，<code>user cinder;</code> 进入库，查看volumes表信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MariaDB [cinder]&gt; select deleted,status,deleted_at from volumes where id=&apos;751b6804-ce57-48d1-bbce-c0b9d4d10a97&apos;;</span><br><span class="line">+---------+----------------+------------+</span><br><span class="line">| deleted | status         | deleted_at |</span><br><span class="line">+---------+----------------+------------+</span><br><span class="line">|       0 | error_deleting | NULL       |</span><br><span class="line">+---------+----------------+------------+</span><br><span class="line">1 row in set (0.01 sec)</span><br></pre></td></tr></table></figure></p>
<p>很多原因可能导致volume 进入error或者error_deleting状态，此时无法再执行delete操作。这种情况大体分为两类：</p>
<ul>
<li>1.当执行cinder delete时，cinder连接不到glusterfs 云硬盘服务器，导致删除失败。</li>
<li>2.当执行cinder delete时，cinder连接不到数据库，此时由于没有事务同步，导致ceph已经删除对应的image，但没有同步状态到数据库中，此时volume可能处于available或者deleting状态，如果再次执行delete操作，显然cinder已经找不到对应的image，所以会抛出错误异常，此时cinder volume会把它设为error_deleting状态，并且无法通过reset-state删除。</li>
</ul>
<p>尝试执行如下命令：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cinder reset-state volume_id</span><br><span class="line">$ cinder delete volume_id</span><br></pre></td></tr></table></figure></p>
<p>如果还是失败<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@openstack-controller ~(keystone_openstack-cloud)]# cinder delete 751b6804-ce57-48d1-bbce-c0b9d4d10a97</span><br><span class="line">Delete for volume 751b6804-ce57-48d1-bbce-c0b9d4d10a97 failed: Invalid volume: Volume status must be available or error or error_restoring or error_extending and must not be migrating, attached, belong to a consistency group or have snapshots. (HTTP 400) (Request-ID: req-1769e1bc-b0bc-4688-bff7-fc88e8785cb0)</span><br><span class="line">ERROR: Unable to delete any of the specified volumes.</span><br></pre></td></tr></table></figure></p>
<p>此故障无法通过cinder命令删除，只能修改数据库状态,标识其为已删除状态（通常不直接删除记录）:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -pxxx</span><br><span class="line"></span><br><span class="line">MariaDB [cinder]&gt; use cinder;</span><br><span class="line"></span><br><span class="line">MariaDB [cinder]&gt; update volumes set deleted=1 where id = &quot;751b6804-ce57-48d1-bbce-c0b9d4d10a97&quot;;</span><br><span class="line"></span><br><span class="line">MariaDB [cinder]&gt; update volumes set status=&apos;deleted&apos; where id = &quot;751b6804-ce57-48d1-bbce-c0b9d4d10a97&quot;;</span><br><span class="line"></span><br><span class="line">MariaDB [cinder]&gt; update volumes set deleted_at=&apos;now()&apos; where id = &quot;751b6804-ce57-48d1-bbce-c0b9d4d10a97&quot;;</span><br><span class="line"></span><br><span class="line">MariaDB [cinder]&gt; select deleted,status,deleted_at from volumes where id=&apos;751b6804-ce57-48d1-bbce-c0b9d4d10a97&apos;;</span><br><span class="line">+---------+---------+---------------------+</span><br><span class="line">| deleted | status  | deleted_at          |</span><br><span class="line">+---------+---------+---------------------+</span><br><span class="line">|       1 | deleted | 0000-00-00 00:00:00 |</span><br><span class="line">+---------+---------+---------------------+</span><br><span class="line">1 row in set (0.00 sec)</span><br></pre></td></tr></table></figure></p>
<p>如上，只需要修改cinder数据库的volumes表，修改deleted字段为1(整型的1，不是字符串)，status字段修改为”deleted”，deleted_at可修改为”now()”,也可以不修改。</p>
<p>再次查看cinder卷信息，已经没有状态为删除错误的信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@openstack-controller ~(keystone_openstack-cloud)]# cinder list|grep error_deleting|wc -l</span><br><span class="line">0</span><br></pre></td></tr></table></figure></p>
<p>最后，删除对应的glusterfs目录下的volume信息：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@openstack-controller (keystone_openstack-cloud)]# ls /var/lib/cinder/glusterfs/c44e08da624e18a5d328451413fd4c27</span><br><span class="line">volume-11cb3510-533e-4db4-9999-ff2c7b72695a  volume-3d07bbcd-c648-4bda-a0ee-96b9877b7a4b  volume-751b6804-ce57-48d1-bbce-c0b9d4d10a97</span><br><span class="line"></span><br><span class="line">[root@openstack-controller (keystone_openstack-cloud)]# du -s -h /var/lib/cinder/glusterfs/c44e08da624e18a5d328451413fd4c27/volume-751b6804-ce57-48d1-bbce-c0b9d4d10a97 </span><br><span class="line">527M  volume-751b6804-ce57-48d1-bbce-c0b9d4d10a97</span><br><span class="line"></span><br><span class="line">[root@openstack-controller (keystone_openstack-cloud)]# rm -f /lib/cinder/glusterfs/c44e08da624e18a5d328451413fd4c27/volume-751b6804-ce57-48d1-bbce-c0b9d4d10a97</span><br></pre></td></tr></table></figure></p>
<p>如此这般，才算解决问题呀！复杂。。。</p>
<h1 id="4-openstack-cinder-volume-error"><a href="#4-openstack-cinder-volume-error" class="headerlink" title="4.openstack cinder volume error"></a>4.openstack cinder volume error</h1><p>事情是这样发生的，我们机房需要断电安装空调，我们关闭openstack所有云主机后，关闭操作系统，重启之后发现，云硬盘都处于error状态，但是不影响正常使用，就是dashboard看着不舒服.<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cinder list|grep error</span><br><span class="line">| 11cb3510-533e-4db4-9999-ff2c7b72695a | error  |   x86-build-glusterfs-1   | 100  |  GlusterFS  |   true   | cbc4f7ab-c167-4478-9982-64909f55e52e |</span><br><span class="line">| 3d07bbcd-c648-4bda-a0ee-96b9877b7a4b | error  | gitlib-server-glusterfs-1 | 1000 |  GlusterFS  |  false   | b232560d-af7a-47f0-80c6-f708b9bda45e |</span><br></pre></td></tr></table></figure></p>
<p>原创文章，转载请注明： 转载自<a href="http://www.itweet.cn" target="_blank" rel="noopener">Itweet</a>的博客<br><code>本博客的文章集合:</code> <a href="http://www.itweet.cn/blog/archive/" target="_blank" rel="noopener">http://www.itweet.cn/blog/archive/</a></p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/openstack/">openstack</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/06/27/Hive-on-Spark-整合测试/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Hive on Spark 整合测试</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2016/06/14/Private-Cloud-personal-workstation/">
        <span class="next-text nav-default">Private Cloud personal workstation</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2019
    <span class="footer-author">Xu Jiang.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/realXuJiang/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
