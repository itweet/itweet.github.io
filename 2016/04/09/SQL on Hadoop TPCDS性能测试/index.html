<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="SQL on Hadoop TPCDS性能测试">




  <meta name="keywords" content="tpcds,">





  <link rel="alternate" href="/atom.xml" title="WHOAMI">




  <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/itweet/itweet.github.io/master/favicon.ico?v=1.1">



<link rel="canonical" href="http://itweet.github.io/2016/04/09/SQL on Hadoop TPCDS性能测试/">


<meta name="description" content="本测试，重点性能测试4个维度，测试对象为主流SQL on Hadoop性能表现，为技术选型做一些参考，由于硬件资源有限，本测试数据集比较小，前提是所有数据保证都能装载到内存.内容还涉及到了SQL on RDBMS 和 SQL on NOSQL性能测试。对一些特殊场景的应用参考。企业级数据仓库解决方案，特别是分析性场景慢慢会被SQL on Hadoop逐渐替代，而且SQL on Hadoop逐渐成熟">
<meta name="keywords" content="tpcds">
<meta property="og:type" content="article">
<meta property="og:title" content="SQL on Hadoop TPCDS性能测试">
<meta property="og:url" content="http://itweet.github.io/2016/04/09/SQL on Hadoop TPCDS性能测试/index.html">
<meta property="og:site_name" content="WHOAMI">
<meta property="og:description" content="本测试，重点性能测试4个维度，测试对象为主流SQL on Hadoop性能表现，为技术选型做一些参考，由于硬件资源有限，本测试数据集比较小，前提是所有数据保证都能装载到内存.内容还涉及到了SQL on RDBMS 和 SQL on NOSQL性能测试。对一些特殊场景的应用参考。企业级数据仓库解决方案，特别是分析性场景慢慢会被SQL on Hadoop逐渐替代，而且SQL on Hadoop逐渐成熟">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://jikelab.github.io/tech-labs/screenshots/TextFile.png">
<meta property="og:image" content="https://jikelab.github.io/tech-labs/screenshots/ParquetFile.png">
<meta property="og:image" content="https://jikelab.github.io/tech-labs/screenshots/ORCFile.png">
<meta property="og:image" content="https://jikelab.github.io/tech-labs/screenshots/ParquetFile-new.png">
<meta property="og:image" content="https://jikelab.github.io/tech-labs/screenshots/SQL-on-NOSQL.png">
<meta property="og:image" content="https://jikelab.github.io/tech-labs/screenshots/table-file-size.png">
<meta property="og:updated_time" content="2018-07-02T13:09:15.495Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SQL on Hadoop TPCDS性能测试">
<meta name="twitter:description" content="本测试，重点性能测试4个维度，测试对象为主流SQL on Hadoop性能表现，为技术选型做一些参考，由于硬件资源有限，本测试数据集比较小，前提是所有数据保证都能装载到内存.内容还涉及到了SQL on RDBMS 和 SQL on NOSQL性能测试。对一些特殊场景的应用参考。企业级数据仓库解决方案，特别是分析性场景慢慢会被SQL on Hadoop逐渐替代，而且SQL on Hadoop逐渐成熟">
<meta name="twitter:image" content="https://jikelab.github.io/tech-labs/screenshots/TextFile.png">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> SQL on Hadoop TPCDS性能测试 - WHOAMI </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">WHOAMI</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/atom.xml">
                            
                            
                                RSS
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          SQL on Hadoop TPCDS性能测试
        
      </h1>

      <time class="post-time">
          4月 09 2016
      </time>
    </header>



    
            <div class="post-content">
            <p>本测试，重点性能测试4个维度，测试对象为主流SQL on Hadoop性能表现，为技术选型做一些参考，由于硬件资源有限，本测试数据集比较小，前提是所有数据保证都能装载到内存.<br>内容还涉及到了SQL on RDBMS 和 SQL on NOSQL性能测试。对一些特殊场景的应用参考。企业级数据仓库解决方案，特别是分析性场景慢慢会被SQL on Hadoop逐渐替代，而且SQL on Hadoop逐渐成熟，可以支持类似Oracle PL/SQL功能。Hive 2.0 已经支持Hive HPL/SQL已经集成，支持存储过程，Impala,SparkSQL也能支持。后两者支持的还不够成熟.<br>SQL on Hadoop在未来会在数据仓库占有非常重要的位置，所以很多传统数据仓库方案慢慢被替代，HadoopDBA职位也会发展起来。SQL on NOSQL(NewSQL)也会替代一部分应用场景。所以技术选型性能测试，为企业选择最有利的SQL on Hadoop架构，构建一栈式大数据解决方案非常重要的一环。</p>
<h1 id="Prerequisites"><a href="#Prerequisites" class="headerlink" title="Prerequisites"></a>Prerequisites</h1><ul>
<li>Hadoop2.x or later cluster</li>
<li>Hive 1.1(Tez)</li>
<li>Impala 2.2</li>
<li>Presto 0.143</li>
<li>Drill 1.6</li>
<li><p>SparkSQL 1.6.1 and 1.5.2 </p>
</li>
<li><p>测试环境4台物理机</p>
<ul>
<li>server1 : CPU total : 32 ; mem total : 126 g ; disk hdfs: 22.4 TiB</li>
<li>server2 : CPU total : 32 ; mem total : 126 g ; disk hdfs: 7.7 TiB TiB</li>
<li>server3 : CPU total : 8  ; mem total : 32 g ; disk hdfs: 500.7 GiB TiB</li>
<li>server4 : CPU total : 8  ; mem total : 32 g ; disk hdfs: 500.7 GiB TiB</li>
</ul>
</li>
</ul>
<h1 id="Compile-and-package-the-appropriate-data-generator"><a href="#Compile-and-package-the-appropriate-data-generator" class="headerlink" title="Compile and package the appropriate data generator."></a>Compile and package the appropriate data generator.</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ git clone https://github.com/hortonworks/hive-testbench.git</span><br><span class="line"></span><br><span class="line">$ cd hive-testbench/</span><br><span class="line"></span><br><span class="line">$ ./tpcds-build.sh</span><br><span class="line"></span><br><span class="line">$ tar -zcvf hive-testbench.tar.gz hive-testbench[</span><br><span class="line"></span><br><span class="line">$ du -sh hive-testbench.tar.gz 133M    hive-testbench.tar.gz</span><br></pre></td></tr></table></figure>
<h1 id="Generate-and-load-the-data"><a href="#Generate-and-load-the-data" class="headerlink" title="Generate and load the data."></a>Generate and load the data.</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">$ tar -zxvf hive-testbench.tar.gz</span><br><span class="line"></span><br><span class="line">$ cd hive-testbench</span><br><span class="line"></span><br><span class="line">$  cat test.sh </span><br><span class="line">FORMAT=rcfile ./tpcds-setup.sh 1000</span><br><span class="line"></span><br><span class="line">$ nohup sh test.sh &gt; test.log &amp;</span><br><span class="line"></span><br><span class="line">$ sh tpc-ds-test.sh</span><br><span class="line">ls: `/tmp/tpcds-generate/1000&apos;: No such file or directory</span><br><span class="line">Generating data at scale factor 1000.</span><br><span class="line">WARNING: Use &quot;yarn jar&quot; to launch YARN applications.</span><br><span class="line">15/11/23 01:28:39 INFO impl.TimelineClientImpl: Timeline service address: http://server2:8188/ws/v1/timeline/</span><br><span class="line">15/11/23 01:28:40 INFO client.RMProxy: Connecting to ResourceManager at server2/192.168.111.201:8050</span><br><span class="line">15/11/23 01:28:40 INFO input.FileInputFormat: Total input paths to process : 1</span><br><span class="line">15/11/23 01:28:40 INFO mapreduce.JobSubmitter: number of splits:1000</span><br><span class="line">15/11/23 01:28:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1448155433956_0001</span><br><span class="line">15/11/23 01:28:41 INFO impl.YarnClientImpl: Submitted application application_1448155433956_0001</span><br><span class="line">15/11/23 01:28:41 INFO mapreduce.Job: The url to track the job: http://server2:8088/proxy/application_1448155433956_0001/</span><br><span class="line">15/11/23 01:28:41 INFO mapreduce.Job: Running job: job_1448155433956_0001</span><br><span class="line">15/11/23 01:28:57 INFO mapreduce.Job: Job job_1448155433956_0001 running in uber mode : false</span><br><span class="line">15/11/23 01:28:57 INFO mapreduce.Job:  map 0% reduce 0%</span><br><span class="line">15/11/23 01:31:53 INFO mapreduce.Job:  map 1% reduce 0%</span><br><span class="line">....省略....</span><br><span class="line">15/11/23 01:31:53 INFO mapreduce.Job:  map 100% reduce 0%</span><br><span class="line">TPC-DS text data generation complete.</span><br><span class="line">Loading text data into external tables.</span><br><span class="line">Optimizing table store_sales (1/24).</span><br><span class="line">Optimizing table store_returns (2/24).</span><br><span class="line">Optimizing table web_sales (3/24).</span><br><span class="line">Optimizing table web_returns (4/24).</span><br><span class="line">Optimizing table catalog_sales (5/24).</span><br><span class="line">Optimizing table catalog_returns (6/24).</span><br><span class="line">Optimizing table inventory (7/24).</span><br><span class="line">Optimizing table date_dim (8/24).</span><br><span class="line">Optimizing table time_dim (9/24).</span><br><span class="line">Optimizing table item (10/24).</span><br><span class="line">Optimizing table customer (11/24).</span><br><span class="line">Optimizing table customer_demographics (12/24).</span><br><span class="line">Optimizing table household_demographics (13/24).</span><br><span class="line">Optimizing table customer_address (14/24).</span><br><span class="line">Optimizing table store (15/24).</span><br><span class="line">Optimizing table promotion (16/24).</span><br><span class="line">Optimizing table warehouse (17/24).</span><br><span class="line">Optimizing table ship_mode (18/24).</span><br><span class="line">Optimizing table reason (19/24).</span><br><span class="line">Optimizing table income_band (20/24).</span><br><span class="line">Optimizing table call_center (21/24).</span><br><span class="line">Optimizing table web_page (22/24).</span><br><span class="line">Optimizing table catalog_page (23/24).</span><br><span class="line">Optimizing table web_site (24/24).</span><br><span class="line">Data loaded into database tpcds_bin_partitioned_rcfile_1000.</span><br></pre></td></tr></table></figure>
<h1 id="Run-queries"><a href="#Run-queries" class="headerlink" title="Run queries."></a>Run queries.</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Hive-tpcds testing:</span><br><span class="line">    修改runSuite.pl脚本，指定自己生成的hive库--&gt;&gt;</span><br><span class="line">    </span><br><span class="line">    $ cat runSuite.pl |grep tpcds_bin_partitioned_</span><br><span class="line">        &apos;tpcds&apos; =&gt; &quot;tpcds_bin_partitioned_rcfile_$scale&quot;,</span><br><span class="line"></span><br><span class="line">    $ sh ./runSuite_hive.sh </span><br><span class="line"></span><br><span class="line">Impala-tpcds testing:</span><br><span class="line">    略。。。</span><br></pre></td></tr></table></figure>
<h1 id="SQL-on-Hadoop性能测试结果"><a href="#SQL-on-Hadoop性能测试结果" class="headerlink" title="SQL-on-Hadoop性能测试结果"></a>SQL-on-Hadoop性能测试结果</h1><ul>
<li><p>Textfile<br> <img src="https://jikelab.github.io/tech-labs/screenshots/TextFile.png" alt><br> 执行时间为0s，说明语法不支持,0.1执行失败，有些是框架本身不稳定(Hive on Spark &amp;&amp; Presto)</p>
</li>
<li><p>Parquet<br> <img src="https://jikelab.github.io/tech-labs/screenshots/ParquetFile.png" alt><br> 执行时间为0s，说明语法不支持,0.1执行失败，有些是框架本身不稳定(Hive on Spark &amp;&amp; Presto)</p>
</li>
<li><p>ORC<br> <img src="https://jikelab.github.io/tech-labs/screenshots/ORCFile.png" alt><br> 执行时间为0s，说明语法不支持,0.1执行失败，有些是框架本身不稳定(Hive on Spark &amp;&amp; Presto)</p>
</li>
<li><p>Parqeut(new version)<br> <img src="https://jikelab.github.io/tech-labs/screenshots/ParquetFile-new.png" alt><br> 执行时间为0s，说明语法不支持,0.1执行失败，有些是框架本身不稳定(Hive on Spark &amp;&amp; Presto)</p>
</li>
</ul>
<h1 id="SQL-on-NOSQL性能测试结果"><a href="#SQL-on-NOSQL性能测试结果" class="headerlink" title="SQL on NOSQL性能测试结果"></a>SQL on NOSQL性能测试结果</h1><p>   <img src="https://jikelab.github.io/tech-labs/screenshots/SQL-on-NOSQL.png" alt><br>   执行时间为0s,表示语法不支持,0.1执行失败;这里测试数据在6000万左右。</p>
<pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Comparison between compression algorithms</span><br><span class="line"></span><br><span class="line">Algorithm    % remaining    Encoding    Decoding</span><br><span class="line">GZIP            0.134       21 MB/s     118 MB/s</span><br><span class="line">LZO             0.205       135 MB/s    410 MB/s</span><br><span class="line">Zippy/Snappy    0.222       172 MB/s    409 MB/s</span><br></pre></td></tr></table></figure>
</code></pre><h1 id="列式存储"><a href="#列式存储" class="headerlink" title="列式存储"></a>列式存储</h1><p>   <img src="https://jikelab.github.io/tech-labs/screenshots/table-file-size.png" alt></p>
<h1 id="执行query和测试数据源"><a href="#执行query和测试数据源" class="headerlink" title="执行query和测试数据源"></a>执行query和测试数据源</h1><p>   <a href="https://jikelab.github.io/tech-labs/2016/03/20/Impala-Hive-performance-tuning/" target="_blank" rel="noopener">Impala - Hive 性能测试和查询优化</a></p>
<h1 id="SQL-on-Hadoop-amp-amp-SQL-on-NOSQL-amp-amp-SQL-on-Hadoop-Join-RDBMS-NOSQL"><a href="#SQL-on-Hadoop-amp-amp-SQL-on-NOSQL-amp-amp-SQL-on-Hadoop-Join-RDBMS-NOSQL" class="headerlink" title="SQL-on-Hadoop &amp;&amp; SQL-on-NOSQL &amp;&amp; SQL on Hadoop Join RDBMS/NOSQL"></a>SQL-on-Hadoop &amp;&amp; SQL-on-NOSQL &amp;&amp; SQL on Hadoop Join RDBMS/NOSQL</h1><p>   <a href="https://github.com/itweet/course/blob/master/Enterprise_Hadoop_Solutions/SQL-on-Hadoop-script.sql" target="_blank" rel="noopener">SQL-on-Hadoop &amp;&amp; SQL-on-NOSQL &amp;&amp; SQL on Hadoop Join RDBMS/NOSQL 脚本文件</a></p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ul>
<li><p>1、为了公平公正，SQL是完全在多种SQL on Hadop框架能正常执行的，在某些框架，无法执行成功，由于语法有细微区别，不支持导致执行时间为0</p>
</li>
<li><p>2、其他情况导致执行时间为0.1，因为框架本身不够稳定(worker节点失去联系)，执行失败，多数SQL on Hadoop框架可以很快执行完成。</p>
</li>
<li><p>3、Presto使用效率确实很不错，但是需要做很多优化参数和底层文件大小考虑，还有一些内存有关参数调节，而且节点压力太大会失去联系，技术性公司出的东西，对orc格式优化最多性能最优。</p>
</li>
<li><p>4、Hive查询hbase表，因为mapjion优化参数导致报错问题？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">hive (default)&gt; set hive.auto.convert.join;</span><br><span class="line">hive.auto.convert.join=true</span><br><span class="line">hive (default)&gt; set hive.auto.convert.join=false;</span><br><span class="line"></span><br><span class="line">hive (default)&gt; set hive.ignore.mapjoin.hint;</span><br><span class="line">hive.ignore.mapjoin.hint=false</span><br><span class="line">hive (default)&gt; set hive.ignore.mapjoin.hint=true;</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>hive 跑join的时候，由于做了优化，忽略mapjoin这种写法，而交给框架自动判断是否mapjoin，发现读取hbase表做join操作，都给转换为mapjoin了，导致内存报错，把自动检测转换mapjoin参数关闭后能正常跑完。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Execution log at: /tmp/hadoop/hadoop_20160403103939_1ee1a162-fa4b-425a-a0ad-f3aaa121e9d1.log</span><br><span class="line">2016-04-03 10:39:29     Starting to launch local task to process map join;      maximum memory = 2025848832</span><br><span class="line">2016-04-03 10:39:38     Processing rows:        200000  Hashtable size: 199999  Memory usage:   571202024       percentage:     0.282</span><br></pre></td></tr></table></figure></p>
<ul>
<li><p>5、SQL-on-Hbase，Hbase+phoenix方案可以执行CRUD，简单事物，保证数据最终一致性，支持完整的事物，完全继承Hbase的权限；场景，Salesforce开源的基于HBase的SQL查询系统。基本原理是将一个对于HBase client来说比较复杂的查询转换成一系列Region Scan，结合coprocessor和custom  filter在多台Region Server上进行并行查询，汇总各个Scan结果。种种迹象表明，Phoenix应该不是个优化的OLAP系统，更像是一个用于简单单表查询，过滤，排 序，检索的OLTP系统。<br>测试总结：</p>
<ul>
<li><p>5.1、为了保证查询尽量分布布到多台服务器，Regions的个数一定要保证分散。</p>
</li>
<li><p>5.2、为了保证数量不会太大,需要建立snappy表，并且保证regions数量多的同时，尽量分散到多台服务器，row_key设计很关键，表压缩保证数据量不会太大，而导致regions大多数时间处于Compaction状态，影响使用性。</p>
</li>
<li><p>5.3、一个region尽量保证在1G大小，默认10G进行split。测试的时候发现如果所有数据集中在一个region，查询就在哪一个节点，无法发挥分布式的优势，而且还有查询不动的倾向，甚至报错。手动做了compaction &amp;&amp; split后，1个regions变成3个，不仅能查询，而且快速返回结果。</p>
</li>
<li><p>5.4 除phoenix方案，之外的其它方案，无法用到hbase的优化器，级别是scan数据到框架内部作处理，这样的缺点是，读取数据耗费太多时间，就是把hbase当做一个后端数据存储系统。而不是一个nosql数据库。性能提升比较难做，瓶颈在regionserver读取数据上，如果是海里数据写出，其它sql on hadoop框架scan读取都是全表扫描，那么对hbase集群压力非常大。无法完全发挥hbase作为一个nosql数据库的优势。</p>
</li>
</ul>
</li>
<li><p>6、在测试中，测试了spark sql 两个版本，非常可喜的事，在spark1.6+版本基本解决了gc严重，shuffle效率低下的问题，join查询一下子有了质的飞跃，具体请参看性能测试图表内容。两个spark版本性能差距非常大，而去同样的sql，同样的硬件环境和数据量。</p>
</li>
<li><p>7、其次apache drill表现也蛮让人眼前一亮的，而且plugin支持度很大，对nosql,rdbms,sql on hadoop等主流数据源都有很好的支持，虽然和prestodb有一定的重合度，但是比presto性能好一些，而且稳定得多，特别对hbase数据源的查询，效率也仅次于phoenix，具体可以看测试结果。</p>
</li>
</ul>
<p><code>以上做了一点总结，由于个人水平有限，难免错漏，还望大家多多反馈。以便我不断修正自己的认知。</code></p>
<p>原创文章，转载请注明： 转载自<a href="http://www.itweet.cn" target="_blank" rel="noopener">Itweet</a>的博客<br><code>本博客的文章集合:</code> <a href="http://www.itweet.cn/blog/archive/" target="_blank" rel="noopener">http://www.itweet.cn/blog/archive/</a></p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/tpcds/">tpcds</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2016/04/11/macbook-pro/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">macbook-pro</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2016/03/20/Impala - Hive 性能测试和查询优化/">
        <span class="next-text nav-default">Impala - Hive 性能测试和查询优化</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2019
    <span class="footer-author">Xu Jiang.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/frostfan/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
