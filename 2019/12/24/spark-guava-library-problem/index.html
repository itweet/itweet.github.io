<!DOCTYPE html>
<html lang="zh-CN">
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="扩展 spark 支持各种新的数据源读写功能，由于 guava 冲突造成的系列问题。">




  <meta name="keywords" content="Spark,2019,">





  <link rel="alternate" href="/atom.xml" title="WHOAMI">




  <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/itweet/itweet.github.io/master/favicon.ico?v=1.1">



<link rel="canonical" href="http://itweet.github.io/2019/12/24/spark-guava-library-problem/">


<meta name="description" content="扩展 spark 支持各种新的数据源读写功能，由于 guava 冲突造成的系列问题。">
<meta name="keywords" content="Spark,2019">
<meta property="og:type" content="article">
<meta property="og:title" content="Spark guava 库引发的系列问题">
<meta property="og:url" content="http://itweet.github.io/2019/12/24/spark-guava-library-problem/index.html">
<meta property="og:site_name" content="WHOAMI">
<meta property="og:description" content="扩展 spark 支持各种新的数据源读写功能，由于 guava 冲突造成的系列问题。">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-12-25T14:39:06.180Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Spark guava 库引发的系列问题">
<meta name="twitter:description" content="扩展 spark 支持各种新的数据源读写功能，由于 guava 冲突造成的系列问题。">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  <script id="baidu_analytics">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?b75d841b3068f7782eac9af2c8c866e7";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-154998721-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-154998721-1');
</script>


    <title> Spark guava 库引发的系列问题 - WHOAMI </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">WHOAMI</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/atom.xml">
                            
                            
                                RSS
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          Spark guava 库引发的系列问题
        
      </h1>

      <time class="post-time">
          12月 24 2019
      </time>
    </header>



    
            <div class="post-content">
            <p>最近在扩展 spark structured streaming 功能的时候，遇到几个疑难问题，今天一并记录一下，方便以后翻旧帐。。。</p>
<p>一切都要从 maven-shade-plugin 插件开始说起，我在扩展 spark structured streaming 功能时，需要充分考虑未来的可扩展性和易用性，最好能沉淀出一个小框架，呈现为一个 lib 库，基于这个库能够快速的扩展新的数据源。</p>
<p>首先，我先调研了一下现有需要支持的数据源，总共 4+，基本都是在公司内部大规模使用的分布式数据存储系统。现有需要实现，数据源需要支持 read -&gt; process -&gt; write 功能。中间 process 需要充分考虑自定义处理逻辑的能力。优先支持流式 API 功能，其次支持批量 API 功能。</p>
<p>经过一番调研和思考，我抽象出 source，process，sink，JobConf 三种接口以及若干方法。source 和 sink 对应 4+ 数据源，每种数据源都会有一个基本的数据对象，支持对象进行读写数据源，读写时支持基本的谓词下推，每种数据源根据存储规则，进行最大化的并行 scan。Process 接口支持基本的数据处理转换方法，基于 spark 的 dataset 进行封装。JobConf 实现配置化数据源信息的自动加载和多方数据来源的 merge，JobConf 实现了类似 SpringBoot 的自动化配置功能，只需要把支持的数据源的相关配置到 <code>xxx-dev.propergies</code>，根据默认配置 job.profiles.active 指定 dev 则默认去 resources 中载入其中的带 <code>xxx.</code> 开头的全部配置，在具体的 API 代码中 new 相关的 source &amp; sink 对象则自动加载相应配置，实现任务的提交和计算。整体打包为一个 shade jar 包，运行时通过 <code>-Djob.config.location = /path/xxx-prod.propergies</code> 在外部实现动态加载配置。</p>
<p>我主要从以下几个方面考虑：</p>
<p>易用性：提交时只需要一个 jar 包和一个外部的配置文件，进行提交任务并计算。</p>
<p>可扩展性：抽象出一个基本的框架，简称：A 模块。新增数据源，只需要依赖基础的 A 模块，配置文件中配置相关 source，sink 配置信息。然后，编写 Process 的业务转换逻辑，利用 JobConf 进行本地调试和上线，能降低大部分的调试功能。</p>
<p>快速入门：A 模块，支持的数据源都提供相互读写、数据缓缓的测试用例，代码级指导，快速扩展新的面相特定业务的模块功能。提供详细的 README 指导如何在 IDEA 和 线上集群发起任务。</p>
<p>进入正题，在使用我提供的库扩展新功能时，主要遇到如下两个问题：</p>
<p>问题1: <code>java.lang.ClassNotFoundException: kafka.DefaultSource</code></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">19/12/23 13:34:54 INFO ApplicationMaster: Unregistering ApplicationMaster with FAILED (diag message: User class threw exception: java.lang.ClassNotFoundException: Failed to find data source: kafka. Please find packages at http://spark.apache.org/third-party-projects.html</span><br><span class="line">	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:639)</span><br><span class="line">	at org.apache.spark.sql.streaming.DataStreamReader.load(DataStreamReader.scala:159)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:498)</span><br><span class="line">	at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721)</span><br><span class="line">Caused by: java.lang.ClassNotFoundException: kafka.DefaultSource</span><br><span class="line">	at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</span><br><span class="line">	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)</span><br><span class="line">	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$23$$anonfun$apply$15.apply(DataSource.scala:622)</span><br><span class="line">	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$23$$anonfun$apply$15.apply(DataSource.scala:622)</span><br><span class="line">	at scala.util.Try$.apply(Try.scala:192)</span><br><span class="line">	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$23.apply(DataSource.scala:622)</span><br><span class="line">	at org.apache.spark.sql.execution.datasources.DataSource$$anonfun$23.apply(DataSource.scala:622)</span><br><span class="line">	at scala.util.Try.orElse(Try.scala:84)</span><br><span class="line">	at org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:622)</span><br><span class="line">	... 11 more</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>我确定，相关 spark structured streaming 依赖的包都已经打进去了，提交任务依然报错。经过一番 Debug，发现时因为我们自己扩展的 spark datasource 代码中有一个文件 <code>resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister</code>, 而 Kafka 的官方扩展里面也有一个名称一样的文件：</p>
<ul>
<li>kafka-0-10-sql： org.apache.spark.sql.kafka010.KafkaSourceProvider</li>
<li>xxx-engine-xxx: org.apache.spark.sql.xxx.xxxSourceProvider</li>
</ul>
<p>因为打包优先级的问题，造成我们的文件覆盖了 Kafka 的文件内容，造成提交到集群时一直报如上错误。Spark 就是依靠此文件中的内容，动态的加载相关的 class 文件，进而实现动态加载自定义数据源的功能。</p>
<p><strong>我们如何解决此问题？</strong></p>
<p>方案一：</p>
<p>在 <code>resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister</code> 文件中，加入 Kafka 以及自己扩展的几个 xxxSourceProvider，可解决问题。</p>
<p>方案二：</p>
<p>使用 maven assembly 和 shade 插件进行同名 service 文件内容合并。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;transformers&gt;</span><br><span class="line">    &lt;transformer implementation=&quot;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&quot;/&gt;</span><br><span class="line">&lt;/transformers&gt;</span><br></pre></td></tr></table></figure>
<p>方案三：</p>
<p>大型工程中，一般避免生成 <code>uber-jar</code> 包，springboot 就是一个例子，网络上面充斥着 springboot 各种 jar 依赖冲突问题。模块划分清晰，生成的 jar 只有自己写的代码，依赖的第三方 lib 统一放到一个文件夹中，写一个脚本去控制启动进程，或发起一个任务。build 直接生成一个tag.gz，自带 jar、配置文件、启动脚本。线上直接解压修改配置就能跑。</p>
<p>问题2: IDEA 运行的非常成功，打成统一的 <code>uber-jar</code> 到线上提交到集群报错：java.lang.NoSuchMethodError: com.google.common.hash.Hashing.farmHashFingerprint64()</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Caused by: java.lang.NoSuchMethodError: com.google.common.hash.Hashing.farmHashFingerprint64()Lcom/google/common/hash/HashFunction;</span><br><span class="line">	at com.aliyun.openservices.aliyun.log.producer.internals.Utils.generateProducerHash(Utils.java:31)</span><br><span class="line">	at com.aliyun.openservices.aliyun.log.producer.LogProducer.&lt;init&gt;(LogProducer.java:91)</span><br></pre></td></tr></table></figure>
<p>遇到此坑的人不在少数：</p>
<ul>
<li><p>SparkR：<a href="https://sparkr.atlassian.net/browse/SPARKR-211" target="_blank" rel="noopener">https://sparkr.atlassian.net/browse/SPARKR-211</a></p>
</li>
<li><p>Hive：<a href="https://issues.apache.org/jira/browse/HIVE-7387" target="_blank" rel="noopener">https://issues.apache.org/jira/browse/HIVE-7387</a></p>
</li>
</ul>
<p>经过一番排查发现我们依赖的一个模块使用 guava 版本 22.0，而 spark 集群自带 14.0，导致冲突，而无法正常工作。做为运行在 spark 集群上的任务，spark 加载 guava 包优先级高于我们自己的包。</p>
<p>我们依赖的包使用到 guava 版本 22.0 中比较新的方法，而在 14.0 版本还没有这样的方法。在不能修改对方代码的前提下，有如下方案：</p>
<ul>
<li>spark 集群的包升级一下，风险较高，容易造成未知问题。</li>
<li>另外一种方式是利用 maven 插件重命名自己的 guava 包。</li>
</ul>
<p>利用 maven 插件 shade 重命名包解决问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;relocations&gt;</span><br><span class="line">    &lt;relocation&gt;</span><br><span class="line">        &lt;pattern&gt;com.google.common&lt;/pattern&gt;</span><br><span class="line">        &lt;shadedPattern&gt;com.xxx.xxx.shaded.com.google.common&lt;/shadedPattern&gt;</span><br><span class="line">    &lt;/relocation&gt;</span><br><span class="line">&lt;/relocations&gt;</span><br></pre></td></tr></table></figure>
<p>如何减少此类问题，依赖大型工程，需要考虑自己项目引入包的版本是否和大型工程依赖的包有冲突，尽量使用下载量最大的版本。避免使用到一些新特性，而造成上面问题。</p>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/Spark/">Spark</a>
		  
			<a href="/tags/2019/">2019</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2020/03/22/lecture1-interoduction/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Lecture1-interoduction</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2019/09/25/Debugging-the-build-process-in-fusiondb-website/">
        <span class="next-text nav-default">Debugging the build process in fusiondb website</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
    <div style="text-align:center;">
        <button class="btn" id="load-disqus" onclick="disqus.load();">加载 Disqus 评论</button>
    </div>
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="//disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2023
    <span class="footer-author">Xu Jiang.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/realXuJiang/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    

<script type="text/javascript">
  var disqus_shortname = 'itweet-cn';
  var disqus_identifier = '2019/12/24/spark-guava-library-problem/';

  var disqus_title = "Spark guava 库引发的系列问题";


  var disqus = {
    load : function disqus(){
        if(typeof DISQUS !== 'object') {
          (function () {
          var s = document.createElement('script'); s.async = true;
          s.type = 'text/javascript';
          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
          }());
          $('#load-disqus').remove(); ///加载后移除按钮
        }
    }
  }

  
    var disqus_config = function () {
        this.page.url = disqus_url;
        this.page.identifier = disqus_identifier;
        this.page.title = disqus_title;
    };
  

</script>


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
