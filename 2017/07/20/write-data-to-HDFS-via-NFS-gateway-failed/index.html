<!DOCTYPE html>
<html lang>
  <head><meta name="generator" content="Hexo 3.8.0">
    
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,minimum-scale=1,maximum-scale=1">


<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="description" content="write-data-to-HDFS-via-NFS-gateway-failed">




  <meta name="keywords" content="NFSGateway,">





  <link rel="alternate" href="/atom.xml" title="WHOAMI">




  <link rel="shortcut icon" type="image/x-icon" href="https://raw.githubusercontent.com/itweet/itweet.github.io/master/favicon.ico?v=1.1">



<link rel="canonical" href="http://itweet.github.io/2017/07/20/write-data-to-HDFS-via-NFS-gateway-failed/">


<meta name="description" content="今天我们聊NFSGateway，近期真的是忙得不可开交，在构建100个节点集群的时，由于一些特殊的业务需求需要使用NFS-Gateway或者HDFS-fuse功能，把HDFS分布式文件系统挂在到某些机器上，可以通过访问Linux本地文件系统操纵HDFS中的数据，这就是类似传统的NFS文件系统的功能。通过把HDFS整个分布式文件系统，挂载到某些Linux机器，通过往挂载的目录中传递数据，即可直接上">
<meta name="keywords" content="NFSGateway">
<meta property="og:type" content="article">
<meta property="og:title" content="write-data-to-HDFS-via-NFS-gateway-failed">
<meta property="og:url" content="http://itweet.github.io/2017/07/20/write-data-to-HDFS-via-NFS-gateway-failed/index.html">
<meta property="og:site_name" content="WHOAMI">
<meta property="og:description" content="今天我们聊NFSGateway，近期真的是忙得不可开交，在构建100个节点集群的时，由于一些特殊的业务需求需要使用NFS-Gateway或者HDFS-fuse功能，把HDFS分布式文件系统挂在到某些机器上，可以通过访问Linux本地文件系统操纵HDFS中的数据，这就是类似传统的NFS文件系统的功能。通过把HDFS整个分布式文件系统，挂载到某些Linux机器，通过往挂载的目录中传递数据，即可直接上">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://github.com/itweet/labs/raw/master/BigData/img/nfsgateway-image114.jpg">
<meta property="og:image" content="https://github.com/itweet/labs/raw/master/BigData/img/nfs.png">
<meta property="og:image" content="https://github.com/itweet/labs/raw/master/common/img/weixin_public.gif">
<meta property="og:updated_time" content="2018-07-02T13:09:15.522Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="write-data-to-HDFS-via-NFS-gateway-failed">
<meta name="twitter:description" content="今天我们聊NFSGateway，近期真的是忙得不可开交，在构建100个节点集群的时，由于一些特殊的业务需求需要使用NFS-Gateway或者HDFS-fuse功能，把HDFS分布式文件系统挂在到某些机器上，可以通过访问Linux本地文件系统操纵HDFS中的数据，这就是类似传统的NFS文件系统的功能。通过把HDFS整个分布式文件系统，挂载到某些Linux机器，通过往挂载的目录中传递数据，即可直接上">
<meta name="twitter:image" content="https://github.com/itweet/labs/raw/master/BigData/img/nfsgateway-image114.jpg">


<link rel="stylesheet" type="text/css" href="/css/style.css?v=1.1">
<link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">





<script type="text/javascript">
  var themeConfig = {
    fancybox: {
      enable: false
    },
  };
</script>




  



    <title> write-data-to-HDFS-via-NFS-gateway-failed - WHOAMI </title>
  </head>

  <body>
    <div id="page">
      <header id="masthead"><div class="site-header-inner">
    <h1 class="site-title">
        <a href="/." class="logo">WHOAMI</a>
    </h1>

    <nav id="nav-top">
        
            <ul id="menu-top" class="nav-top-items">
                
                    <li class="menu-item">
                        <a href="/archives">
                            
                            
                                Archives
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/about">
                            
                            
                                About
                            
                        </a>
                    </li>
                
                    <li class="menu-item">
                        <a href="/atom.xml">
                            
                            
                                RSS
                            
                        </a>
                    </li>
                
            </ul>
        
  </nav>
</div>

      </header>
      <div id="content">
        
    <div id="primary">
        
  <article class="post">
    <header class="post-header">
      <h1 class="post-title">
        
          write-data-to-HDFS-via-NFS-gateway-failed
        
      </h1>

      <time class="post-time">
          7月 20 2017
      </time>
    </header>



    
            <div class="post-content">
            <p><img src="https://github.com/itweet/labs/raw/master/BigData/img/nfsgateway-image114.jpg" alt="nfsgateway-114"></p>
<p>今天我们聊NFSGateway，近期真的是忙得不可开交，在构建100个节点集群的时，由于一些特殊的业务需求需要使用NFS-Gateway或者HDFS-fuse功能，把HDFS分布式文件系统挂在到某些机器上，可以通过访问Linux本地文件系统操纵HDFS中的数据，这就是类似传统的<code>NFS</code>文件系统的功能。通过把HDFS整个分布式文件系统，挂载到某些Linux机器，通过往挂载的目录中传递数据，即可直接上传到HDFS，让HDFS的使用方式非常的方便。</p>
<p>目前开源世界有很多分布式文件系统的优秀软件，比如：Ceph，Glusterfs,Alluxio等都提供了类似nfs，fuse挂载分布式文件系统到Linux主机的能力，也都大量复用了Linux本身已经有的软件，所以都是兼容NFS,FUSE的接口的。HDFS也不例外，也都通过类似的技术来支持这样的功能。</p>
<p>在HDFS中目前提供了两种方式：</p>
<ul>
<li><p>HDFS-NFSGateway  在HDP版本中原生支持此方式</p>
</li>
<li><p>HDFS-Fuse</p>
</li>
</ul>
<h3 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h3><ul>
<li>HDP 2.6.1.0-129</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hdp-select versions</span><br><span class="line">2.6.1.0-129</span><br></pre></td></tr></table></figure>
<ul>
<li>Linux</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.2.1511 (Core)</span><br></pre></td></tr></table></figure>
<h3 id="NFSGateway安装"><a href="#NFSGateway安装" class="headerlink" title="NFSGateway安装"></a>NFSGateway安装</h3><p>通过<code>ambari</code>界面自动化去安装<code>NFSGateway</code>的方法，在Ambari管理的最新的Hadoop2.x以上的版本都是支持这种方式的，并且在界面上可以自动化安装<code>NFSGateway</code>。</p>
<p>首先，登录ambari-server的可视化界面，点击“Hosts”，任意选择一个主机单机。</p>
<p>其次，点击<code>+Add</code>按钮，选择<code>NFSGateway</code>，点击<code>Confirm Add</code>进行安装NFSGateway。</p>
<p>最后，点击<code>Start</code>按钮，启动NFSGateway。</p>
<p>手动教程参考：<a href="http://itweet.cn/blog/2014/02/04/HDFS_NFS_Gateway" target="_blank" rel="noopener">http://itweet.cn/blog/2014/02/04/HDFS_NFS_Gateway</a></p>
<h3 id="NFSGateway挂载"><a href="#NFSGateway挂载" class="headerlink" title="NFSGateway挂载"></a>NFSGateway挂载</h3><p>首次挂载遇到如下问题，环境是<code>Centos 7.2</code>我亲自安装的，采用的是最小化的安装Linux系统模式，而集群的版本<code>HDP 2.6.1.0-129</code>。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># mount -t nfs -o vers=3,proto=tcp,nolock localhost:/ /hdfs</span><br><span class="line">mount: wrong fs type, bad option, bad superblock on localhost:/,</span><br><span class="line">       missing codepage or helper program, or other error</span><br><span class="line">       (for several filesystems (e.g. nfs, cifs) you might</span><br><span class="line">       need a /sbin/mount.&lt;type&gt; helper program)</span><br><span class="line"></span><br><span class="line">       In some cases useful info is found in syslog - try</span><br><span class="line">       dmesg | tail or so.</span><br></pre></td></tr></table></figure>
<p>根据提示，并且进一步排除<code>/sbin/mount.&lt;type&gt;</code>目录发现，根本没有<code>mount.&lt;type&gt;</code>的文件，进而断定为缺少<code>nfs-utils</code>软件包，安装即解决问题。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># yum install nfs-utils</span><br></pre></td></tr></table></figure>
<p>NFSGateway挂载，HDFS分布式文件系统挂载到本地系统挂载点为<code>/hdfs</code>，如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># mkdir /hdfs</span><br><span class="line"># mount -t nfs -o vers=3,proto=tcp,nolock localhost:/ /hdfs</span><br><span class="line"></span><br><span class="line"># df -h|grep hdfs</span><br><span class="line">localhost:/     4.8T  3.2G  4.8T   1% /hdfs</span><br></pre></td></tr></table></figure></p>
<h3 id="NFSGateway测试"><a href="#NFSGateway测试" class="headerlink" title="NFSGateway测试"></a>NFSGateway测试</h3><p>NFSGateway挂载成功之后，我们对他进行一些基本的读写测试，看是否满足我们的要求，让HDFS分布式文件系统的访问，就像访问Linux本地目录一样简单。</p>
<p><img src="https://github.com/itweet/labs/raw/master/BigData/img/nfs.png" alt="nfs"></p>
<p><strong><em>例如：</em></strong></p>
<ol>
<li>测试cp数据到目录</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@bigdata-server-1 ~]# su - hdfs</span><br><span class="line">[hdfs@bigdata-server-1 ~]$ echo aaa &gt; test.txt</span><br></pre></td></tr></table></figure>
<p>测试cp文件到挂载点(<code>/hdfs</code>)的属于分布式文件系统的<code>/hdfs/tmp</code>，出现错误，表现的现象为无法正常cp数据到此目录，并且在<code>hdfs</code>看到生成此相关文件大小为0<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ cp test.txt /hdfs/tmp/</span><br><span class="line">cp: cannot create regular file ‘/hdfs/tmp/test.txt’: Input/output error</span><br></pre></td></tr></table></figure></p>
<p>既然是NFS的问题，首先排查<code>NFS</code>服务相关日志，定位问题，发现如下警告信息。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># tail -300 /var/log/hadoop/root/hadoop-hdfs-nfs3-bigdata-server-1.log</span><br></pre></td></tr></table></figure></p>
<p><code>cannot create regular file ‘/hdfs/tmp/test.txt’: Input/output error</code>关键错误信息如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">2017-07-20 22:01:52,737 WARN  oncrpc.RpcProgram (RpcProgram.java:messageReceived(172)) - Invalid RPC call program 100227</span><br><span class="line">2017-07-20 22:04:08,184 WARN  nfs3.RpcProgramNfs3 (RpcProgramNfs3.java:setattr(471)) - Exception </span><br><span class="line">org.apache.hadoop.ipc.RemoteException(java.io.IOException):Access time for hdfs is not configured.  Please set dfs.namenode.accesstime.precision configuration parameter. </span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.FSDirAttrOp.setTimes(FSDirAttrOp.java:105)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setTimes(FSNamesystem.java:2081)</span><br><span class="line">	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setTimes(NameNodeRpcServer.java:1361)</span><br><span class="line">	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setTimes(ClientNamenodeProtocolServerSideTranslatorPB.java:926)</span><br><span class="line">	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)</span><br><span class="line">	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:640)</span><br><span class="line">	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:982)</span><br><span class="line">	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2351)</span><br><span class="line">	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2347)</span><br><span class="line">	at java.security.AccessController.doPrivileged(Native Method)</span><br><span class="line">	at javax.security.auth.Subject.doAs(Subject.java:415)</span><br><span class="line">	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1866)</span><br><span class="line">	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2345)</span><br><span class="line"></span><br><span class="line">	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1554)</span><br><span class="line">	at org.apache.hadoop.ipc.Client.call(Client.java:1498)</span><br><span class="line">	at org.apache.hadoop.ipc.Client.call(Client.java:1398)</span><br><span class="line">	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:233)</span><br><span class="line">	at com.sun.proxy.$Proxy14.setTimes(Unknown Source)</span><br><span class="line">	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.setTimes(ClientNamenodeProtocolTranslatorPB.java:901)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)</span><br><span class="line">	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)</span><br><span class="line">	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)</span><br><span class="line">	at java.lang.reflect.Method.invoke(Method.java:606)</span><br><span class="line">	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:291)</span><br><span class="line">	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:203)</span><br><span class="line">	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:185)</span><br><span class="line">	at com.sun.proxy.$Proxy15.setTimes(Unknown Source)</span><br><span class="line">	at org.apache.hadoop.hdfs.DFSClient.setTimes(DFSClient.java:3211)</span><br><span class="line">	at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.setattrInternal(RpcProgramNfs3.java:401)</span><br><span class="line">	at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.setattr(RpcProgramNfs3.java:465)</span><br><span class="line">	at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.setattr(RpcProgramNfs3.java:407)</span><br><span class="line">	at org.apache.hadoop.hdfs.nfs.nfs3.RpcProgramNfs3.handleInternal(RpcProgramNfs3.java:2193)</span><br><span class="line">	at org.apache.hadoop.oncrpc.RpcProgram.messageReceived(RpcProgram.java:184)</span><br><span class="line">	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)</span><br><span class="line">	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)</span><br><span class="line">	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)</span><br><span class="line">	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:281)</span><br><span class="line">	at org.apache.hadoop.oncrpc.RpcUtil$RpcMessageParserStage.messageReceived(RpcUtil.java:132)</span><br><span class="line">	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)</span><br><span class="line">	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)</span><br><span class="line">	at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:787)</span><br><span class="line">	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)</span><br><span class="line">	at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:462)</span><br><span class="line">	at org.jboss.netty.handler.codec.frame.FrameDecoder.callDecode(FrameDecoder.java:443)</span><br><span class="line">	at org.jboss.netty.handler.codec.frame.FrameDecoder.messageReceived(FrameDecoder.java:303)</span><br><span class="line">	at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)</span><br><span class="line">	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:560)</span><br><span class="line">	at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:555)</span><br><span class="line">	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)</span><br><span class="line">	at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)</span><br><span class="line">	at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)</span><br><span class="line">	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)</span><br><span class="line">	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)</span><br><span class="line">	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)</span><br><span class="line">	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)</span><br><span class="line">	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)</span><br><span class="line">	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</span><br><span class="line">	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</span><br><span class="line">	at java.lang.Thread.run(Thread.java:745)</span><br></pre></td></tr></table></figure></p>
<p>根据日志定位问题，发现日志中有相关提示<code>dfs.namenode.accesstime.precision</code>需要进行配置，在去查看相关配置的含义。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">The access time for HDFS file is precise upto this value. The default value is 1 hour. Setting a value of 0 disables access times for HDFS.</span><br></pre></td></tr></table></figure>
<p>理解之后，通过调整，在<code>Ambari-Web</code>中查看发现默认值 <code>dfs.namenode.accesstime.precision = 0</code> 改为 <code>dfs.namenode.accesstime.precision = 3600000</code>，根据提示重启集群相关受影响的足迹，即解决问题。</p>
<p>再次进行测试，发现此报错消失。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ echo aaa &gt; text.2</span><br><span class="line"></span><br><span class="line">$ cp text.2 /hdfs/tmp/</span><br><span class="line"></span><br><span class="line">$ cat /hdfs/tmp/text.2 </span><br><span class="line">aaa</span><br></pre></td></tr></table></figure></p>
<p>到此，通过<code>touch、echo、cp、cat、mv</code>等命令测试，依然正常使用，基本的nfs功能测试完成。</p>
<h3 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h3><p>NFSGateway的功能相对来说是非常不错的，降低使用HDFS成本的特性，如上我总结的在配置NFSGateway遇到的一些小问题，因为对于几百个节点的HDFS集群来说，有NFS这样的特性，可以让很多Gateway服务器通过FTP-Server接收海量数据，只要进入FTP就进入HDFS集群，这样HDFS入库就变得特别简单，可以节省时间。后续集内容会提供数据对比深度剖析HDFS提供的类似NFSGateway功能的软件性能情况和原理。</p>
<p>事物都是两面性的，带来便利的同时也会带来一定的代价，使用此软件会导致数据传输性能降低很多。在使用<code>dd</code>命令测试结果如下：</p>
<p>我通过<code>dd</code>命令生成一个10G的大文件，让后通过<code>hdfs fs put</code>这样的命令，对比三者的上传性能。</p>
<ul>
<li>HDFS-NFSGateway 86 MB/秒</li>
<li>HDFS-Fuse 132 MB/秒</li>
<li>HDFS-PUT 310 MB/秒</li>
</ul>
<p>如上，Hadoop原生提供的<code>put</code>命令上传效率最高，其次是Fuse，最差的是NFSGateway，这是在5台服务器万兆网络(9.84 Gbits/sec)测试的结果，仅作为参考。</p>
<p>综上所述，我仅仅提供了一些基础的测试数据和结论，使用非原生提供的API进行数据接入，虽然方便了很多，但是性能有很大损耗，这个就是权衡的结果，看是否在你的业务忍耐限度以内，选择哪种方案，得通过数据和相关业务经验结合选择最合适的。</p>
<p>写到这里，内容相对浅显，后续我会对多方测试结果进行整理汇总，发布一版更加有力的测试数据对比情况。最近我也在做一些MPP数据库的测试优化，后续会有更多精彩的生产环境经验积累，原创文章发布，敬请关注。</p>
<p>欢迎关注微信公众号，第一时间，阅读更多有关云计算、大数据文章。<br><img src="https://github.com/itweet/labs/raw/master/common/img/weixin_public.gif" alt="Itweet公众号"></p>
<p>原创文章，转载请注明： 转载自<a href="http://www.itweet.cn" target="_blank" rel="noopener">Itweet</a>的博客<br><code>本博客的文章集合:</code> <a href="http://www.itweet.cn/blog/archive/" target="_blank" rel="noopener">http://www.itweet.cn/blog/archive/</a></p>
<p><strong>参考：</strong></p>
<ul>
<li>[1]. <a href="http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html" target="_blank" rel="noopener">http://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/HdfsNfsGateway.html</a></li>
<li>[2]. <a href="https://discuss.pivotal.io/hc/en-us/articles/204185008-Write-data-to-HDFS-via-NFS-gateway-failed-with-Input-output-error-" target="_blank" rel="noopener">https://discuss.pivotal.io/hc/en-us/articles/204185008-Write-data-to-HDFS-via-NFS-gateway-failed-with-Input-output-error-</a></li>
<li>[3]. <a href="https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml" target="_blank" rel="noopener">https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml</a></li>
<li>[4]. <a href="https://hortonworks.com/blog/simplifying-data-management-nfs-access-to-hdfs/" target="_blank" rel="noopener">https://hortonworks.com/blog/simplifying-data-management-nfs-access-to-hdfs/</a></li>
<li>[5]. <a href="http://apprize.info/php/hadoop_1/6.html" target="_blank" rel="noopener">http://apprize.info/php/hadoop_1/6.html</a></li>
</ul>

            </div>
          

    
      <footer class="post-footer">
		
		<div class="post-tags">
		  
			<a href="/tags/NFSGateway/">NFSGateway</a>
		  
		</div>
		

        
        
  <nav class="post-nav">
    
      <a class="prev" href="/2017/07/27/ Enterprise-BigData-platform-deployment-guide-part-1/">
        <i class="iconfont icon-left"></i>
        <span class="prev-text nav-default">Enterprise-BigData-platform-deployment-guide-part-1</span>
        <span class="prev-text nav-mobile">Prev</span>
      </a>
    
    
      <a class="next" href="/2017/07/14/apache-hive1-vs-hive2-llap-performance/">
        <span class="next-text nav-default">apache-hive1-vs-hive2-llap-performance</span>
        <span class="prev-text nav-mobile">Next</span>
        <i class="iconfont icon-right"></i>
      </a>
    
  </nav>

        
  <div class="comments" id="comments">
    
  </div>


      </footer>
    
  </article>

    </div>

      </div>

      <footer id="colophon"><span class="copyright-year">
    
        &copy;
    
        2014 -
    
    2019
    <span class="footer-author">Xu Jiang.</span>
    <span class="power-by">
        Powered by <a class="hexo-link" href="https://hexo.io/">Hexo</a> and <a class="theme-link" href="https://github.com/frostfan/hexo-theme-polarbear">Polar Bear</a>
    </span>
</span>

      </footer>

      <div class="back-to-top" id="back-to-top">
        <i class="iconfont icon-up"></i>
      </div>
    </div>
    


    




  
    <script type="text/javascript" src="/lib/jquery/jquery-3.1.1.min.js"></script>
  

  

    <script type="text/javascript" src="/js/src/theme.js?v=1.1"></script>
<script type="text/javascript" src="/js/src/bootstrap.js?v=1.1"></script>

  </body>
</html>
